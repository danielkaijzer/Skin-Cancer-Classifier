{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install torch torchvision efficientnet-pytorch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:20:40.421986Z","iopub.execute_input":"2024-12-08T08:20:40.422499Z","iopub.status.idle":"2024-12-08T08:20:40.437624Z","shell.execute_reply.started":"2024-12-08T08:20:40.422460Z","shell.execute_reply":"2024-12-08T08:20:40.436244Z"}},"outputs":[],"execution_count":119},{"cell_type":"markdown","source":"# In this notebook I create two models:\n- A tabular only model that is intended to be used to predict target based on only user input and the features generated by my image_feature_extractor.py program (uses OpenCV to extract geometric and color features from image directly).\n- A hybrid model that combines my tabular model with a CNN by concatinating CNN feature embeddings with tabular data to retrain the tabular model.","metadata":{}},{"cell_type":"code","source":"import os\nimport itertools\nfrom pathlib import Path\nimport time\nfrom tqdm import tqdm\nimport h5py\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport joblib\nimport pandas as pd\nimport polars as pl\nimport pickle\nimport json\nfrom io import BytesIO\nimport timm\nfrom torchvision import transforms\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import VotingClassifier\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline\nimport lightgbm as lgb\nfrom sklearn.utils.class_weight import compute_sample_weight\nfrom torch.utils.data.sampler import WeightedRandomSampler\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom PIL import Image\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-12-09T06:00:29.279267Z","iopub.execute_input":"2024-12-09T06:00:29.279678Z","iopub.status.idle":"2024-12-09T06:00:29.287438Z","shell.execute_reply.started":"2024-12-09T06:00:29.279641Z","shell.execute_reply":"2024-12-09T06:00:29.286565Z"},"trusted":true},"outputs":[],"execution_count":232},{"cell_type":"code","source":"root = Path('/kaggle/input/isic-2024-challenge')\n\ntrain_path = root / 'train-metadata.csv'\ntest_path = root / 'test-metadata.csv'\nsubm_path = root / 'sample_submission.csv'\n\nid_col = 'isic_id'\ntarget_col = 'target'\ngroup_col = 'patient_id'\n\nerr = 1e-5\nsampling_ratio = 0.01\nseed = 42","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T06:00:29.444767Z","iopub.execute_input":"2024-12-09T06:00:29.445302Z","iopub.status.idle":"2024-12-09T06:00:29.450026Z","shell.execute_reply.started":"2024-12-09T06:00:29.445274Z","shell.execute_reply":"2024-12-09T06:00:29.449161Z"}},"outputs":[],"execution_count":233},{"cell_type":"markdown","source":"# Model 1 - Tabular only model","metadata":{}},{"cell_type":"code","source":"user_input_features_num = [\n    # User Input Features\n    'age_approx',                  # Ask user for age\n    # 'sex',                         # Ask user for sex\n    # 'anatom_site_general',         # Ask user to put in anatomical site (from list of options)\n    'clin_size_long_diam_mm',      # Ask user for size of lesion in mm\n    #'tbp_lv_location',\t           # Classification of anatomical location, divides arms & legs to upper & lower; torso into thirds.+\n    #'tbp_lv_location_simple',\t   # Classification of anatomical location, simple.+\n]\n\ncv_features = [\n    # Shape\n    'tbp_lv_areaMM2',                    # Area of lesion (mm^2).+\n    'tbp_lv_perimeterMM',                # Perimeter of lesion (mm).+\n\n    'tbp_lv_minorAxisMM',\t             # Smallest lesion diameter (mm).+ AXIS OF LEAST SECOND MOMENT!\n    'tbp_lv_eccentricity',               # Eccentricity. (use min_inertia line and max_inertia line)\n    'tbp_lv_area_perim_ratio',           # Border jaggedness, the ratio between lesions perimeter and area. Circular lesions will have low values; irregular shaped lesions will have higher values. Values range 0-10.+\n    \n    # Color Features\n    'tbp_lv_A',\t                         # A inside lesion.+\n    'tbp_lv_Aext',\t                     # A outside lesion.+\n    'tbp_lv_B',                          # B inside lesion.+\n    'tbp_lv_Bext',                       # B outside lesion.+\n    'tbp_lv_C',                          # Chroma inside  lesion.+\n    'tbp_lv_Cext',                       # Chroma outside lesion.+\n    'tbp_lv_H',                          # Hue inside the lesion; calculated as the angle of A* and B* in LAB* color space. Typical values range from 25 (red) to 75 (brown).+\n    'tbp_lv_Hext',                       # Hue outside lesion.+\n    'tbp_lv_L',                          # L inside lesion.+\n    'tbp_lv_Lext',                       # L outside lesion.+\n    \n    'tbp_lv_deltaA',\t           # Average A contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaB',               # Color difference\n    'tbp_lv_deltaL',\t           # Average L contrast (inside vs. outside lesion).+\n    # 'tbp_lv_stdL',\t               # Standard deviation of L inside lesion.+\n    # 'tbp_lv_stdLExt',\t           # Standard deviation of L outside lesion.+\n    'tbp_lv_deltaLBnorm',          # Contrast between the lesion and its immediate surrounding skin. Low contrast lesions tend to be faintly visible such as freckles; high contrast lesions tend to be those with darker pigment. Calculated as the average delta LB of the lesion relative to its immediate background in LAB* color space. Typical values range from 5.5 to 25.+\n    # 'tbp_lv_color_std_mean',\t   # Color irregularity, calculated as the variance of colors within the lesion's boundary.\n\n    # Harder to implement\n    # 'tbp_lv_radial_color_std_max',\t     # Color asymmetry, a measure of asymmetry of the spatial distribution of color within the lesion. This score is calculated by looking at the average standard deviation in LAB* color space within concentric rings originating from the lesion center. Values range 0-10.+\n    # 'tbp_lv_symm_2axis',\t             # Border asymmetry; a measure of asymmetry of the lesion's contour about an axis perpendicular to the lesion's most symmetric axis. Lesions with two axes of symmetry will therefore have low scores (more symmetric), while lesions with only one or zero axes of symmetry will have higher scores (less symmetric). This score is calculated by comparing opposite halves of the lesion contour over many degrees of rotation. The angle where the halves are most similar identifies the principal axis of symmetry, while the second axis of symmetry is perpendicular to the principal axis. Border asymmetry is reported as the asymmetry value about this second axis. Values range 0-10.+\n    # 'tbp_lv_symm_2axis_angle',\t         # Lesion border asymmetry angle.+\n    # 'tbp_lv_norm_border',\t       # Border irregularity (0-10 scale); the normalized average of border jaggedness and asymmetry.+\n    # 'tbp_lv_norm_color',\t       # Color variation (0-10 scale); the normalized average of color asymmetry and color irregularity.+\n\n    \n]\n\nderived_features = [\n    'lesion_size_ratio',             # tbp_lv_minorAxisMM      / clin_size_long_diam_mm\n    'lesion_shape_index',            # tbp_lv_areaMM2          / tbp_lv_perimeterMM **2\n    'hue_contrast',                  # tbp_lv_H                - tbp_lv_Hext              abs\n    'luminance_contrast',            # tbp_lv_L                - tbp_lv_Lext              abs\n    'lesion_color_difference',       # tbp_lv_deltaA **2       + tbp_lv_deltaB **2 + tbp_lv_deltaL **2  sqrt  \n    'perimeter_to_area_ratio',       # tbp_lv_perimeterMM      / tbp_lv_areaMM2\n    'area_to_perimeter_ratio',       # tbp_lv_areaMM2          / tbp_lv_perimeterMM\n    # 'color_consistency',             # tbp_lv_stdL             / tbp_lv_Lext\n    # 'consistency_color',             # tbp_lv_stdL*tbp_lv_Lext / tbp_lv_stdL + tbp_lv_Lext\n    'size_age_interaction',          # clin_size_long_diam_mm  * age_approx\n    # 'hue_color_std_interaction',     # tbp_lv_H                * tbp_lv_color_std_mean\n    'color_contrast_index',          # tbp_lv_deltaA + tbp_lv_deltaB + tbp_lv_deltaL + tbp_lv_deltaLBnorm\n    'log_lesion_area',               # tbp_lv_areaMM2          + 1  np.log\n    'normalized_lesion_size',        # clin_size_long_diam_mm  / age_approx\n    'mean_hue_difference',           # tbp_lv_H                + tbp_lv_Hext    / 2\n    'std_dev_contrast',              # tbp_lv_deltaA **2 + tbp_lv_deltaB **2 + tbp_lv_deltaL **2   / 3  np.sqrt\n    'overall_color_difference',      # tbp_lv_deltaA           + tbp_lv_deltaB + tbp_lv_deltaL   / 3\n    # 'color_variance_ratio',          # tbp_lv_color_std_mean   / tbp_lv_stdLExt\n    'size_color_contrast_ratio',     # clin_size_long_diam_mm  / tbp_lv_deltaLBnorm\n    'color_range',                   # abs(tbp_lv_L - tbp_lv_Lext) + abs(tbp_lv_A - tbp_lv_Aext) + abs(tbp_lv_B - tbp_lv_Bext)\n    # 'shape_color_consistency',       # tbp_lv_eccentricity     * tbp_lv_color_std_mean\n    'border_length_ratio',           # tbp_lv_perimeterMM      / pi * sqrt(tbp_lv_areaMM2 / pi)\n\n    # # Harder to implement\n    # 'age_size_symmetry_index',       # age_approx              * clin_size_long_diam_mm * tbp_lv_symm_2axis\n    # 'index_age_size_symmetry',       # age_approx              * tbp_lv_areaMM2 * tbp_lv_symm_2axis\n    # 'color_asymmetry_index',         # tbp_lv_symm_2axis       * tbp_lv_radial_color_std_max\n    # 'color_shape_composite_index',   # tbp_lv_color_std_mean   + bp_lv_area_perim_ratio + tbp_lv_symm_2axis   / 3\n    # 'symmetry_perimeter_interaction',# tbp_lv_symm_2axis       * tbp_lv_perimeterMM\n    # 'comprehensive_lesion_index',    # tbp_lv_area_perim_ratio + tbp_lv_eccentricity + bp_lv_norm_color + tbp_lv_symm_2axis   / 4\n    # 'border_color_interaction',      # tbp_lv_norm_border      * tbp_lv_norm_color\n    # 'border_color_interaction_2',\n    # 'lesion_severity_index',         # tbp_lv_norm_border      + tbp_lv_norm_color + tbp_lv_eccentricity / 3\n    # 'shape_complexity_index',        # border_complexity       + lesion_shape_index\n    # 'lesion_visibility_score',       # tbp_lv_deltaLBnorm      + tbp_lv_norm_color\n    # 'symmetry_border_consistency',   # tbp_lv_symm_2axis       * tbp_lv_norm_border\n    # 'consistency_symmetry_border',   # tbp_lv_symm_2axis       * tbp_lv_norm_border / (tbp_lv_symm_2axis + tbp_lv_norm_border)\n    # 'border_complexity',             # tbp_lv_norm_border      + tbp_lv_symm_2axis\n    # 'color_uniformity',              # tbp_lv_color_std_mean   / tbp_lv_radial_color_std_max\n]\n\n# Categoric USER INPUT\ncat_cols = ['sex', 'anatom_site_general', 'tbp_lv_location', 'tbp_lv_location_simple']\n\nnew_feature_cols = user_input_features_num + cat_cols + cv_features + derived_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T06:00:29.714856Z","iopub.execute_input":"2024-12-09T06:00:29.715301Z","iopub.status.idle":"2024-12-09T06:00:29.726110Z","shell.execute_reply.started":"2024-12-09T06:00:29.715273Z","shell.execute_reply":"2024-12-09T06:00:29.725292Z"}},"outputs":[],"execution_count":234},{"cell_type":"code","source":"def read_data(path):\n    return (\n        pl.read_csv(path)\n        .with_columns(\n            pl.col('age_approx').cast(pl.String).replace('NA', np.nan).cast(pl.Float64),\n        )\n        .with_columns(\n            pl.col(pl.Float64).fill_nan(pl.col(pl.Float64).median()),\n        )\n        .with_columns(\n            # Basic derived features we can calculate\n            lesion_size_ratio              = pl.col('tbp_lv_minorAxisMM') / pl.col('clin_size_long_diam_mm'),\n            lesion_shape_index             = pl.col('tbp_lv_areaMM2') / (pl.col('tbp_lv_perimeterMM') ** 2),\n            hue_contrast                   = (pl.col('tbp_lv_H') - pl.col('tbp_lv_Hext')).abs(),\n            luminance_contrast             = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs(),\n            lesion_color_difference        = (pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2).sqrt(),\n        )\n        .with_columns(\n            perimeter_to_area_ratio        = pl.col('tbp_lv_perimeterMM') / pl.col('tbp_lv_areaMM2'),\n            area_to_perimeter_ratio        = pl.col('tbp_lv_areaMM2') / pl.col('tbp_lv_perimeterMM'),\n            # color_consistency              = pl.col('tbp_lv_stdL') / pl.col('tbp_lv_Lext'),\n            # consistency_color              = pl.col('tbp_lv_stdL') * pl.col('tbp_lv_Lext') / (pl.col('tbp_lv_stdL') + pl.col('tbp_lv_Lext')),\n            size_age_interaction           = pl.col('clin_size_long_diam_mm') * pl.col('age_approx'),\n            # hue_color_std_interaction      = pl.col('tbp_lv_H') * pl.col('tbp_lv_color_std_mean'),\n        )\n        .with_columns(\n            color_contrast_index           = pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL') + pl.col('tbp_lv_deltaLBnorm'),\n            log_lesion_area                = (pl.col('tbp_lv_areaMM2') + 1).log(),\n            normalized_lesion_size         = pl.col('clin_size_long_diam_mm') / pl.col('age_approx'),\n            mean_hue_difference            = (pl.col('tbp_lv_H') + pl.col('tbp_lv_Hext')) / 2,\n            std_dev_contrast               = ((pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2) / 3).sqrt(),\n            overall_color_difference       = (pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL')) / 3,\n        )\n        .with_columns(\n            # color_variance_ratio           = pl.col('tbp_lv_color_std_mean') / pl.col('tbp_lv_stdLExt'),\n            size_color_contrast_ratio      = pl.col('clin_size_long_diam_mm') / pl.col('tbp_lv_deltaLBnorm'),\n            color_range                    = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs() + (pl.col('tbp_lv_A') - pl.col('tbp_lv_Aext')).abs() + (pl.col('tbp_lv_B') - pl.col('tbp_lv_Bext')).abs(),\n            # shape_color_consistency        = pl.col('tbp_lv_eccentricity') * pl.col('tbp_lv_color_std_mean'),\n            border_length_ratio            = pl.col('tbp_lv_perimeterMM') / (2 * np.pi * (pl.col('tbp_lv_areaMM2') / np.pi).sqrt()),\n        ) # HARDER ONES AHEAD:\n        # .with_columns(\n        #     age_size_symmetry_index        = pl.col('age_approx') * pl.col('clin_size_long_diam_mm') * pl.col('tbp_lv_symm_2axis'),\n        #     index_age_size_symmetry        = pl.col('age_approx') * pl.col('tbp_lv_areaMM2') * pl.col('tbp_lv_symm_2axis'),\n        #     color_asymmetry_index          = pl.col('tbp_lv_radial_color_std_max') * pl.col('tbp_lv_symm_2axis'),\n        #     color_shape_composite_index    = (pl.col('tbp_lv_color_std_mean') + pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_symm_2axis')) / 3,\n        #     symmetry_perimeter_interaction = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_perimeterMM'),\n        #     comprehensive_lesion_index     = (pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_eccentricity') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_symm_2axis')) / 4,\n        #     border_color_interaction       = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color'),\n        #     border_color_interaction_2     = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color') / (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color')),\n        #     lesion_severity_index          = (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_eccentricity')) / 3,\n        #     shape_complexity_index         = pl.col('border_complexity') + pl.col('lesion_shape_index'),\n        #     lesion_visibility_score        = pl.col('tbp_lv_deltaLBnorm') + pl.col('tbp_lv_norm_color'),\n        #     symmetry_border_consistency    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border'),\n        #     consistency_symmetry_border    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border') / (pl.col('tbp_lv_symm_2axis') + pl.col('tbp_lv_norm_border')),\n        #     border_complexity              = pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_symm_2axis'),\n        #     color_uniformity               = pl.col('tbp_lv_color_std_mean') / (pl.col('tbp_lv_radial_color_std_max') + err),\n        # )\n        .to_pandas()\n        .set_index(id_col)\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T06:00:29.861199Z","iopub.execute_input":"2024-12-09T06:00:29.861516Z","iopub.status.idle":"2024-12-09T06:00:29.873301Z","shell.execute_reply.started":"2024-12-09T06:00:29.861493Z","shell.execute_reply":"2024-12-09T06:00:29.872339Z"}},"outputs":[],"execution_count":235},{"cell_type":"code","source":"lgb_params = {\n    'objective':        'binary',\n    'verbosity':        -1,\n    'n_iter':           200,\n    'n_jobs':           2,\n    'boosting_type':    'gbdt',\n    'lambda_l1':        0.03335206514282942, \n    'lambda_l2':        0.005157393323802471, \n    'learning_rate':    0.030665870185795318, \n    'max_depth':        7, \n    'num_leaves':       239, \n    'colsample_bytree': 0.7573175155547233, \n    'colsample_bynode': 0.5005423904042993, \n    'bagging_fraction': 0.7937347683420382, \n    'bagging_freq':     4, \n    'min_data_in_leaf': 29, \n    'scale_pos_weight': 1.648349898918236,\n}\n\n\nestimator = VotingClassifier([\n    ('lgb1', Pipeline([\n        ('sampler', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=12)),\n        ('classifier', lgb.LGBMClassifier(**lgb_params, random_state=12)),\n    ])),\n    ('lgb2', Pipeline([\n        ('sampler', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=22)),\n        ('classifier', lgb.LGBMClassifier(**lgb_params, random_state=22)),\n    ])),\n    ('lgb3', Pipeline([\n        ('sampler', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=32)),\n        ('classifier', lgb.LGBMClassifier(**lgb_params, random_state=32)),\n    ])),\n    ('lgb4', Pipeline([\n        ('sampler', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=42)),\n        ('classifier', lgb.LGBMClassifier(**lgb_params, random_state=42)),\n    ])),\n    ('lgb5', Pipeline([\n        ('sampler', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=52)),\n        ('classifier', lgb.LGBMClassifier(**lgb_params, random_state=52)),\n    ])),\n], voting='soft')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T06:00:30.006601Z","iopub.execute_input":"2024-12-09T06:00:30.006918Z","iopub.status.idle":"2024-12-09T06:00:30.026236Z","shell.execute_reply.started":"2024-12-09T06:00:30.006893Z","shell.execute_reply":"2024-12-09T06:00:30.025550Z"}},"outputs":[],"execution_count":236},{"cell_type":"code","source":"def custom_metric(estimator, X, y_true):\n    y_hat = estimator.predict_proba(X)[:, 1]\n    min_tpr = 0.80\n    max_fpr = abs(1 - min_tpr)\n    \n    v_gt = abs(y_true - 1)\n    v_pred = np.array([1.0 - x for x in y_hat])\n    \n    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n    \n    return partial_auc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T06:00:30.404920Z","iopub.execute_input":"2024-12-09T06:00:30.405714Z","iopub.status.idle":"2024-12-09T06:00:30.410881Z","shell.execute_reply.started":"2024-12-09T06:00:30.405683Z","shell.execute_reply":"2024-12-09T06:00:30.409948Z"}},"outputs":[],"execution_count":237},{"cell_type":"code","source":"def preprocess(df_train, df_test, cat_cols, new_feature_cols):\n    # Cast original categorical columns\n    for col in cat_cols:\n        df_train[col] = df_train[col].astype('category')\n        df_test[col] = df_test[col].astype('category')\n    \n    encoder = OneHotEncoder(sparse_output=False, dtype=np.int32, handle_unknown='ignore')\n    encoder.fit(df_train[cat_cols])\n    \n    new_cat_cols = [f'onehot_{i}' for i in range(len(encoder.get_feature_names_out()))]\n    \n    # Directly assign the transformed arrays\n    df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n    df_train[new_cat_cols] = df_train[new_cat_cols].astype('category')\n    df_test[new_cat_cols] = encoder.transform(df_test[cat_cols])\n    df_test[new_cat_cols] = df_test[new_cat_cols].astype('category')\n\n    # Update feature columns\n    updated_feature_cols = [col for col in new_feature_cols if col not in cat_cols]\n    updated_feature_cols.extend(new_cat_cols)\n\n    joblib.dump(encoder, 'encoder.pkl')\n    with open('feature_columns.json', 'w') as f:\n        json.dump({\n            \"cat_cols\": new_cat_cols,\n            \"new_feature_cols\": updated_feature_cols\n        }, f)\n        \n    return df_train, df_test, new_cat_cols, updated_feature_cols","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T06:00:30.719400Z","iopub.execute_input":"2024-12-09T06:00:30.719746Z","iopub.status.idle":"2024-12-09T06:00:30.726631Z","shell.execute_reply.started":"2024-12-09T06:00:30.719719Z","shell.execute_reply":"2024-12-09T06:00:30.725693Z"}},"outputs":[],"execution_count":238},{"cell_type":"code","source":"def custom_cross_val(estimator, X, y, cv, groups):\n    importances = []\n    scores = []\n    splits = list(cv.split(X, y, groups))\n    \n    # Progress bar for folds\n    fold_iterator = tqdm(enumerate(splits), \n                        total=5, \n                        desc=\"Folds\",\n                        position=0)\n    \n    # for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X, y, groups)):\n    for fold_idx, (train_idx, val_idx) in fold_iterator:\n        fold_start_time = time.time()\n        \n        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n        \n        # Fit the model\n        estimator.fit(X_train, y_train)\n        \n        # Get scores\n        score = custom_metric(estimator, X_val, y_val)\n        scores.append(score)\n        \n        # Extract and store feature importances from each LightGBM model\n        fold_importance = np.zeros(len(new_feature_cols))\n        \n        # for name, pipeline in estimator.named_estimators_.items():\n        for name, pipeline in estimator.named_estimators_.items(): \n            lgb_model = pipeline.named_steps['classifier']\n            fold_importance += lgb_model.feature_importances_\n        \n        importances.append(fold_importance / len(estimator.named_estimators_))\n        \n        fold_time = time.time() - fold_start_time\n        print(f\"Fold {fold_idx + 1} completed in {fold_time:.2f} seconds\")\n        \n        # Update fold progress bar with timing info\n        fold_iterator.set_postfix({'Score': f'{score:.4f}'})\n    \n    print('\\n')\n    return np.array(scores), np.array(importances)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T06:00:31.116110Z","iopub.execute_input":"2024-12-09T06:00:31.116456Z","iopub.status.idle":"2024-12-09T06:00:31.123938Z","shell.execute_reply.started":"2024-12-09T06:00:31.116418Z","shell.execute_reply":"2024-12-09T06:00:31.123080Z"}},"outputs":[],"execution_count":239},{"cell_type":"code","source":"df_train = read_data(train_path)\ndf_competition_test = read_data(test_path)\ndf_subm = pd.read_csv(subm_path, index_col=id_col)\n\ndf_train, df_competition_test, cat_cols, new_feature_cols = preprocess(df_train, df_competition_test, cat_cols, new_feature_cols)\n\n# Create holdout and continue as before\ndf_positive = df_train[df_train['target'] == 1]\ndf_negative = df_train[df_train['target'] == 0]\n\ntest_pos_size = int(0.1 * len(df_positive))\ndf_test_positive = df_positive.sample(n=test_pos_size, random_state=42)\ndf_train_positive = df_positive.drop(df_test_positive.index)\n\ndf_test_negative = df_negative.sample(n=test_pos_size, random_state=42)\ndf_train_negative = df_negative.drop(df_test_negative.index)\n\ndf_test = pd.concat([df_test_positive, df_test_negative], ignore_index=True).sample(frac=1, random_state=42)\ndf_train = pd.concat([df_train_positive, df_train_negative], ignore_index=True).sample(frac=1, random_state=42)\n\nX = df_train[new_feature_cols]\ny = df_train[target_col]\ngroups = df_train[group_col]\ncv = StratifiedGroupKFold(5, shuffle=True, random_state=seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T06:00:32.241103Z","iopub.execute_input":"2024-12-09T06:00:32.241567Z","iopub.status.idle":"2024-12-09T06:00:36.799946Z","shell.execute_reply.started":"2024-12-09T06:00:32.241539Z","shell.execute_reply":"2024-12-09T06:00:36.799150Z"}},"outputs":[],"execution_count":240},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T06:01:44.900730Z","iopub.execute_input":"2024-12-09T06:01:44.901051Z","iopub.status.idle":"2024-12-09T06:01:44.982589Z","shell.execute_reply.started":"2024-12-09T06:01:44.901025Z","shell.execute_reply":"2024-12-09T06:01:44.981670Z"}},"outputs":[{"execution_count":243,"output_type":"execute_result","data":{"text/plain":"        age_approx  clin_size_long_diam_mm  tbp_lv_areaMM2  \\\n17847         80.0                    2.74        4.372302   \n209585        60.0                    9.13       27.453556   \n202064        75.0                    4.25        7.975230   \n171342        65.0                    2.59        4.053293   \n344250        50.0                    3.10        4.559955   \n...            ...                     ...             ...   \n259178        55.0                    3.29        7.093263   \n365838        55.0                    2.60        4.222181   \n131932        55.0                    3.87        9.176206   \n146867        80.0                    4.87        8.425596   \n121958        45.0                    3.33        4.822668   \n\n        tbp_lv_perimeterMM  tbp_lv_minorAxisMM  tbp_lv_eccentricity  \\\n17847             9.420487            2.191781             0.680063   \n209585           23.872196            3.736990             0.923051   \n202064           12.500660            2.328767             0.812933   \n171342            8.999792            2.199336             0.642109   \n344250            8.952786            1.937279             0.803514   \n...                    ...                 ...                  ...   \n259178           10.095683            2.465753             0.597408   \n365838            7.870664            2.054795             0.603512   \n131932           11.291290            2.976213             0.637141   \n146867           14.017250            2.617907             0.859545   \n121958            9.354010            1.818043             0.827651   \n\n        tbp_lv_area_perim_ratio   tbp_lv_A  tbp_lv_Aext   tbp_lv_B  ...  \\\n17847                 20.297220  17.320270    14.017710  29.256130  ...   \n209585                20.758029  21.628310    10.168158  37.833219  ...   \n202064                19.593990  18.658840    17.396250  24.560550  ...   \n171342                19.982828  20.323963    17.244356  28.085807  ...   \n344250                17.577450  16.198720    14.167720  25.286010  ...   \n...                         ...        ...          ...        ...  ...   \n259178                14.368959  18.903081    13.470260  24.052698  ...   \n365838                14.671885  16.891008    14.745181  16.769671  ...   \n131932                13.893890  20.056750    12.951640  32.592500  ...   \n146867                23.319800  24.251860    21.976400  31.738420  ...   \n121958                18.142960  13.886250    10.443970  24.683460  ...   \n\n        onehot_28  onehot_29  onehot_30  onehot_31  onehot_32  onehot_33  \\\n17847           1          0          0          0          0          0   \n209585          0          0          0          0          0          0   \n202064          0          0          0          0          0          1   \n171342          1          0          0          0          0          0   \n344250          0          0          0          0          0          0   \n...           ...        ...        ...        ...        ...        ...   \n259178          0          0          0          0          0          0   \n365838          0          0          0          0          0          1   \n131932          0          0          0          0          0          0   \n146867          0          0          0          0          1          0   \n121958          1          0          0          0          0          0   \n\n        onehot_34  onehot_35  onehot_36  onehot_37  \n17847           0          0          1          0  \n209585          0          0          1          0  \n202064          0          0          0          0  \n171342          0          0          1          0  \n344250          1          0          0          0  \n...           ...        ...        ...        ...  \n259178          1          0          0          0  \n365838          0          0          0          0  \n131932          0          1          0          0  \n146867          0          0          0          0  \n121958          0          0          1          0  \n\n[400981 rows x 76 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age_approx</th>\n      <th>clin_size_long_diam_mm</th>\n      <th>tbp_lv_areaMM2</th>\n      <th>tbp_lv_perimeterMM</th>\n      <th>tbp_lv_minorAxisMM</th>\n      <th>tbp_lv_eccentricity</th>\n      <th>tbp_lv_area_perim_ratio</th>\n      <th>tbp_lv_A</th>\n      <th>tbp_lv_Aext</th>\n      <th>tbp_lv_B</th>\n      <th>...</th>\n      <th>onehot_28</th>\n      <th>onehot_29</th>\n      <th>onehot_30</th>\n      <th>onehot_31</th>\n      <th>onehot_32</th>\n      <th>onehot_33</th>\n      <th>onehot_34</th>\n      <th>onehot_35</th>\n      <th>onehot_36</th>\n      <th>onehot_37</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>17847</th>\n      <td>80.0</td>\n      <td>2.74</td>\n      <td>4.372302</td>\n      <td>9.420487</td>\n      <td>2.191781</td>\n      <td>0.680063</td>\n      <td>20.297220</td>\n      <td>17.320270</td>\n      <td>14.017710</td>\n      <td>29.256130</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>209585</th>\n      <td>60.0</td>\n      <td>9.13</td>\n      <td>27.453556</td>\n      <td>23.872196</td>\n      <td>3.736990</td>\n      <td>0.923051</td>\n      <td>20.758029</td>\n      <td>21.628310</td>\n      <td>10.168158</td>\n      <td>37.833219</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>202064</th>\n      <td>75.0</td>\n      <td>4.25</td>\n      <td>7.975230</td>\n      <td>12.500660</td>\n      <td>2.328767</td>\n      <td>0.812933</td>\n      <td>19.593990</td>\n      <td>18.658840</td>\n      <td>17.396250</td>\n      <td>24.560550</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>171342</th>\n      <td>65.0</td>\n      <td>2.59</td>\n      <td>4.053293</td>\n      <td>8.999792</td>\n      <td>2.199336</td>\n      <td>0.642109</td>\n      <td>19.982828</td>\n      <td>20.323963</td>\n      <td>17.244356</td>\n      <td>28.085807</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>344250</th>\n      <td>50.0</td>\n      <td>3.10</td>\n      <td>4.559955</td>\n      <td>8.952786</td>\n      <td>1.937279</td>\n      <td>0.803514</td>\n      <td>17.577450</td>\n      <td>16.198720</td>\n      <td>14.167720</td>\n      <td>25.286010</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>259178</th>\n      <td>55.0</td>\n      <td>3.29</td>\n      <td>7.093263</td>\n      <td>10.095683</td>\n      <td>2.465753</td>\n      <td>0.597408</td>\n      <td>14.368959</td>\n      <td>18.903081</td>\n      <td>13.470260</td>\n      <td>24.052698</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>365838</th>\n      <td>55.0</td>\n      <td>2.60</td>\n      <td>4.222181</td>\n      <td>7.870664</td>\n      <td>2.054795</td>\n      <td>0.603512</td>\n      <td>14.671885</td>\n      <td>16.891008</td>\n      <td>14.745181</td>\n      <td>16.769671</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>131932</th>\n      <td>55.0</td>\n      <td>3.87</td>\n      <td>9.176206</td>\n      <td>11.291290</td>\n      <td>2.976213</td>\n      <td>0.637141</td>\n      <td>13.893890</td>\n      <td>20.056750</td>\n      <td>12.951640</td>\n      <td>32.592500</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>146867</th>\n      <td>80.0</td>\n      <td>4.87</td>\n      <td>8.425596</td>\n      <td>14.017250</td>\n      <td>2.617907</td>\n      <td>0.859545</td>\n      <td>23.319800</td>\n      <td>24.251860</td>\n      <td>21.976400</td>\n      <td>31.738420</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>121958</th>\n      <td>45.0</td>\n      <td>3.33</td>\n      <td>4.822668</td>\n      <td>9.354010</td>\n      <td>1.818043</td>\n      <td>0.827651</td>\n      <td>18.142960</td>\n      <td>13.886250</td>\n      <td>10.443970</td>\n      <td>24.683460</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>400981 rows × 76 columns</p>\n</div>"},"metadata":{}}],"execution_count":243},{"cell_type":"code","source":"# Run cross validation with timing\nprint(\"Starting cross-validation...\")\ntotal_start_time = time.time()\n\n# Run cross validation\nscores, all_fold_importances = custom_cross_val(\n    estimator=estimator,\n    X=X, \n    y=y,\n    cv=cv,\n    groups=groups\n)\n\ntotal_time = time.time() - total_start_time\n# Print timing results\nprint(f\"\\nTraining Complete!\")\nprint(f\"Total time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")\n\n# Print scores (equivalent to your original output)\nprint(f\"\\nModel Performance:\")\nprint(f\"Mean score: {np.mean(scores):.4f}\")\nprint(f\"Score std: {np.std(scores):.4f}\")\nprint(f\"All scores: {scores}\")\n\n# Print feature importances\nmean_importances = all_fold_importances.mean(axis=0)\nimportance_df = pd.DataFrame({\n    'feature': new_feature_cols,\n    'importance': mean_importances\n}).sort_values('importance', ascending=False)\n\nprint(\"\\nTop 50 Most Important Features:\")\nprint(importance_df.head(50))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T02:56:20.895090Z","iopub.execute_input":"2024-12-09T02:56:20.895645Z","iopub.status.idle":"2024-12-09T02:57:18.279026Z","shell.execute_reply.started":"2024-12-09T02:56:20.895618Z","shell.execute_reply":"2024-12-09T02:57:18.278122Z"}},"outputs":[{"name":"stdout","text":"Starting cross-validation...\n","output_type":"stream"},{"name":"stderr","text":"Folds:  20%|██        | 1/5 [00:10<00:42, 10.73s/it, Score=0.1535]","output_type":"stream"},{"name":"stdout","text":"Fold 1 completed in 10.72 seconds\n","output_type":"stream"},{"name":"stderr","text":"Folds:  40%|████      | 2/5 [00:21<00:31, 10.52s/it, Score=0.1524]","output_type":"stream"},{"name":"stdout","text":"Fold 2 completed in 10.38 seconds\n","output_type":"stream"},{"name":"stderr","text":"Folds:  60%|██████    | 3/5 [00:32<00:22, 11.00s/it, Score=0.1688]","output_type":"stream"},{"name":"stdout","text":"Fold 3 completed in 11.58 seconds\n","output_type":"stream"},{"name":"stderr","text":"Folds:  80%|████████  | 4/5 [00:44<00:11, 11.30s/it, Score=0.1695]","output_type":"stream"},{"name":"stdout","text":"Fold 4 completed in 11.75 seconds\n","output_type":"stream"},{"name":"stderr","text":"Folds: 100%|██████████| 5/5 [00:56<00:00, 11.23s/it, Score=0.1452]","output_type":"stream"},{"name":"stdout","text":"Fold 5 completed in 11.71 seconds\n\n\n\nTraining Complete!\nTotal time: 57.37 seconds (0.96 minutes)\n\nModel Performance:\nMean score: 0.1579\nScore std: 0.0096\nAll scores: [0.15354879 0.152416   0.16877795 0.1694917  0.14521481]\n\nTop 50 Most Important Features:\n                      feature  importance\n18              tbp_lv_deltaB      273.96\n13                   tbp_lv_H      263.08\n8                 tbp_lv_Aext      259.92\n34   overall_color_difference      254.00\n21          lesion_size_ratio      245.72\n29       color_contrast_index      245.60\n15                   tbp_lv_L      240.80\n16                tbp_lv_Lext      239.16\n1      clin_size_long_diam_mm      238.16\n5         tbp_lv_eccentricity      235.68\n23               hue_contrast      233.68\n20         tbp_lv_deltaLBnorm      229.56\n14                tbp_lv_Hext      218.80\n9                    tbp_lv_B      213.32\n32        mean_hue_difference      213.20\n7                    tbp_lv_A      210.08\n17              tbp_lv_deltaA      207.04\n10                tbp_lv_Bext      206.60\n31     normalized_lesion_size      199.48\n28       size_age_interaction      193.76\n35  size_color_contrast_ratio      193.12\n12                tbp_lv_Cext      185.12\n11                   tbp_lv_C      184.16\n6     tbp_lv_area_perim_ratio      176.96\n0                  age_approx      171.44\n22         lesion_shape_index      169.00\n36                color_range      167.48\n19              tbp_lv_deltaL      163.24\n25    lesion_color_difference      162.28\n4          tbp_lv_minorAxisMM      162.04\n26    perimeter_to_area_ratio      153.48\n3          tbp_lv_perimeterMM      152.16\n2              tbp_lv_areaMM2      145.16\n24         luminance_contrast      141.88\n27    area_to_perimeter_ratio      134.40\n37        border_length_ratio      119.80\n33           std_dev_contrast      100.76\n30            log_lesion_area       83.56\n43                   onehot_5       46.56\n47                   onehot_9       26.36\n66                  onehot_28       25.72\n59                  onehot_21       23.48\n40                   onehot_2       21.24\n44                   onehot_6       20.28\n68                  onehot_30       18.48\n62                  onehot_24       17.80\n39                   onehot_1       17.68\n65                  onehot_27       17.24\n72                  onehot_34       16.08\n46                   onehot_8       15.72\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":169},{"cell_type":"markdown","source":"### Training Final Model (Tabular only)","metadata":{}},{"cell_type":"code","source":"# X, y = df_train[feature_cols], df_train[target_col]\nX, y = df_train[new_feature_cols], df_train[target_col]\n\nestimator.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2024-12-09T02:38:30.124398Z","iopub.execute_input":"2024-12-09T02:38:30.125005Z","iopub.status.idle":"2024-12-09T02:38:39.089589Z","shell.execute_reply.started":"2024-12-09T02:38:30.124977Z","shell.execute_reply":"2024-12-09T02:38:39.088629Z"},"trusted":true},"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"VotingClassifier(estimators=[('lgb1',\n                              Pipeline(steps=[('sampler',\n                                               RandomUnderSampler(random_state=12,\n                                                                  sampling_strategy=0.01)),\n                                              ('classifier',\n                                               LGBMClassifier(bagging_fraction=0.7937347683420382,\n                                                              bagging_freq=4,\n                                                              colsample_bynode=0.5005423904042993,\n                                                              colsample_bytree=0.7573175155547233,\n                                                              lambda_l1=0.03335206514282942,\n                                                              lambda_l2=0.005157393323802471,\n                                                              learning_rate...\n                                                              bagging_freq=4,\n                                                              colsample_bynode=0.5005423904042993,\n                                                              colsample_bytree=0.7573175155547233,\n                                                              lambda_l1=0.03335206514282942,\n                                                              lambda_l2=0.005157393323802471,\n                                                              learning_rate=0.030665870185795318,\n                                                              max_depth=7,\n                                                              min_data_in_leaf=29,\n                                                              n_iter=200,\n                                                              n_jobs=2,\n                                                              num_leaves=239,\n                                                              objective='binary',\n                                                              random_state=52,\n                                                              scale_pos_weight=1.648349898918236,\n                                                              verbosity=-1))]))],\n                 voting='soft')","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lgb1&#x27;,\n                              Pipeline(steps=[(&#x27;sampler&#x27;,\n                                               RandomUnderSampler(random_state=12,\n                                                                  sampling_strategy=0.01)),\n                                              (&#x27;classifier&#x27;,\n                                               LGBMClassifier(bagging_fraction=0.7937347683420382,\n                                                              bagging_freq=4,\n                                                              colsample_bynode=0.5005423904042993,\n                                                              colsample_bytree=0.7573175155547233,\n                                                              lambda_l1=0.03335206514282942,\n                                                              lambda_l2=0.005157393323802471,\n                                                              learning_rate...\n                                                              bagging_freq=4,\n                                                              colsample_bynode=0.5005423904042993,\n                                                              colsample_bytree=0.7573175155547233,\n                                                              lambda_l1=0.03335206514282942,\n                                                              lambda_l2=0.005157393323802471,\n                                                              learning_rate=0.030665870185795318,\n                                                              max_depth=7,\n                                                              min_data_in_leaf=29,\n                                                              n_iter=200,\n                                                              n_jobs=2,\n                                                              num_leaves=239,\n                                                              objective=&#x27;binary&#x27;,\n                                                              random_state=52,\n                                                              scale_pos_weight=1.648349898918236,\n                                                              verbosity=-1))]))],\n                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lgb1&#x27;,\n                              Pipeline(steps=[(&#x27;sampler&#x27;,\n                                               RandomUnderSampler(random_state=12,\n                                                                  sampling_strategy=0.01)),\n                                              (&#x27;classifier&#x27;,\n                                               LGBMClassifier(bagging_fraction=0.7937347683420382,\n                                                              bagging_freq=4,\n                                                              colsample_bynode=0.5005423904042993,\n                                                              colsample_bytree=0.7573175155547233,\n                                                              lambda_l1=0.03335206514282942,\n                                                              lambda_l2=0.005157393323802471,\n                                                              learning_rate...\n                                                              bagging_freq=4,\n                                                              colsample_bynode=0.5005423904042993,\n                                                              colsample_bytree=0.7573175155547233,\n                                                              lambda_l1=0.03335206514282942,\n                                                              lambda_l2=0.005157393323802471,\n                                                              learning_rate=0.030665870185795318,\n                                                              max_depth=7,\n                                                              min_data_in_leaf=29,\n                                                              n_iter=200,\n                                                              n_jobs=2,\n                                                              num_leaves=239,\n                                                              objective=&#x27;binary&#x27;,\n                                                              random_state=52,\n                                                              scale_pos_weight=1.648349898918236,\n                                                              verbosity=-1))]))],\n                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgb1</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=12, sampling_strategy=0.01)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.7937347683420382, bagging_freq=4,\n               colsample_bynode=0.5005423904042993,\n               colsample_bytree=0.7573175155547233,\n               lambda_l1=0.03335206514282942, lambda_l2=0.005157393323802471,\n               learning_rate=0.030665870185795318, max_depth=7,\n               min_data_in_leaf=29, n_iter=200, n_jobs=2, num_leaves=239,\n               objective=&#x27;binary&#x27;, random_state=12,\n               scale_pos_weight=1.648349898918236, verbosity=-1)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgb2</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=22, sampling_strategy=0.01)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.7937347683420382, bagging_freq=4,\n               colsample_bynode=0.5005423904042993,\n               colsample_bytree=0.7573175155547233,\n               lambda_l1=0.03335206514282942, lambda_l2=0.005157393323802471,\n               learning_rate=0.030665870185795318, max_depth=7,\n               min_data_in_leaf=29, n_iter=200, n_jobs=2, num_leaves=239,\n               objective=&#x27;binary&#x27;, random_state=22,\n               scale_pos_weight=1.648349898918236, verbosity=-1)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgb3</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=32, sampling_strategy=0.01)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.7937347683420382, bagging_freq=4,\n               colsample_bynode=0.5005423904042993,\n               colsample_bytree=0.7573175155547233,\n               lambda_l1=0.03335206514282942, lambda_l2=0.005157393323802471,\n               learning_rate=0.030665870185795318, max_depth=7,\n               min_data_in_leaf=29, n_iter=200, n_jobs=2, num_leaves=239,\n               objective=&#x27;binary&#x27;, random_state=32,\n               scale_pos_weight=1.648349898918236, verbosity=-1)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgb4</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=42, sampling_strategy=0.01)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.7937347683420382, bagging_freq=4,\n               colsample_bynode=0.5005423904042993,\n               colsample_bytree=0.7573175155547233,\n               lambda_l1=0.03335206514282942, lambda_l2=0.005157393323802471,\n               learning_rate=0.030665870185795318, max_depth=7,\n               min_data_in_leaf=29, n_iter=200, n_jobs=2, num_leaves=239,\n               objective=&#x27;binary&#x27;, random_state=42,\n               scale_pos_weight=1.648349898918236, verbosity=-1)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgb5</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=52, sampling_strategy=0.01)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.7937347683420382, bagging_freq=4,\n               colsample_bynode=0.5005423904042993,\n               colsample_bytree=0.7573175155547233,\n               lambda_l1=0.03335206514282942, lambda_l2=0.005157393323802471,\n               learning_rate=0.030665870185795318, max_depth=7,\n               min_data_in_leaf=29, n_iter=200, n_jobs=2, num_leaves=239,\n               objective=&#x27;binary&#x27;, random_state=52,\n               scale_pos_weight=1.648349898918236, verbosity=-1)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":111},{"cell_type":"markdown","source":"### Save model using Pickle","metadata":{}},{"cell_type":"code","source":"with open('model.pkl', 'wb') as file:\n    pickle.dump(estimator, file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T02:38:41.747267Z","iopub.execute_input":"2024-12-09T02:38:41.747613Z","iopub.status.idle":"2024-12-09T02:38:41.818342Z","shell.execute_reply.started":"2024-12-09T02:38:41.747588Z","shell.execute_reply":"2024-12-09T02:38:41.817480Z"}},"outputs":[],"execution_count":112},{"cell_type":"code","source":"# # Filter the data point after preprocessing\n# data_point = df_train.loc[[\"ISIC_0082829\"]]\n\n# # Extract features\n# X_point = data_point[new_feature_cols]\n\n\n\n\n# # Get the probability of the target\n# probability = estimator.predict_proba(X_point)\n\n# # Extract probability for the positive class\n# positive_class_prob = probability[0][1]\n\n# print(f\"Data point features ({X_point.shape[1]}): {X_point.columns.tolist()}\")\n\n# print(f\"Probability of target being 1: {positive_class_prob}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T02:38:52.982134Z","iopub.execute_input":"2024-12-09T02:38:52.982955Z","iopub.status.idle":"2024-12-09T02:38:52.986779Z","shell.execute_reply.started":"2024-12-09T02:38:52.982924Z","shell.execute_reply":"2024-12-09T02:38:52.985656Z"}},"outputs":[],"execution_count":113},{"cell_type":"markdown","source":"# Hybrid model","metadata":{}},{"cell_type":"code","source":"train_h5 = root / 'train-image.hdf5'\ntest_h5 = root / 'test-image.hdf5'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T02:42:59.840858Z","iopub.execute_input":"2024-12-09T02:42:59.841675Z","iopub.status.idle":"2024-12-09T02:42:59.845585Z","shell.execute_reply.started":"2024-12-09T02:42:59.841645Z","shell.execute_reply":"2024-12-09T02:42:59.844724Z"}},"outputs":[],"execution_count":129},{"cell_type":"code","source":"# Configuration for CNN\nCNN_CONFIG = {\n    \"img_size\": 224,\n    \"batch_size\": 32,\n    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n    \"pretrained_model\": \"efficientnet_b0\",\n    \"embedding_size\": 1792\n}\n\ndef print_gpu_memory():\n    if torch.cuda.is_available():\n        print(f\"GPU Memory allocated: {torch.cuda.memory_allocated()/1024**2:.1f}MB\")\n        print(f\"GPU Memory cached: {torch.cuda.memory_reserved()/1024**2:.1f}MB\")\n\ndef calculate_pauc(y_true, y_pred, min_tpr=0.80):\n    \"\"\"Calculate partial AUC score matching your custom metric\"\"\"\n    max_fpr = abs(1 - min_tpr)\n    \n    # Convert to numpy arrays if they're tensors\n    if torch.is_tensor(y_true):\n        y_true = y_true.cpu().numpy()\n    if torch.is_tensor(y_pred):\n        y_pred = y_pred.cpu().numpy()\n    \n    # Ensure y_true is flattened\n    y_true = y_true.flatten()\n    y_pred = y_pred.flatten()\n    \n    # Match your custom metric calculation\n    v_gt = abs(y_true - 1)\n    v_pred = 1.0 - y_pred\n    \n    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n    \n    return partial_auc\n\n# Define Image Dataset\nclass ISICImageDatasetHDF5(Dataset):\n    def __init__(self, h5_path, df, transforms=None):\n        self.h5_path = h5_path\n        self.df = df\n        self.transforms = transforms\n        self.isic_ids = df['isic_id'].values\n        self.targets = df['target'].values\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        isic_id = self.isic_ids[idx]\n        with h5py.File(self.h5_path, \"r\") as h5_file:\n            img_data = h5_file[isic_id][()]\n        img = Image.open(BytesIO(img_data))\n        img = np.array(img)\n    \n        if self.transforms:\n            augmented = self.transforms(image=img)\n            img = augmented[\"image\"]\n    \n        target = torch.tensor(self.targets[idx], dtype=torch.float32)\n        return img, target\n\n# Load Pretrained CNN\nclass EmbeddingModel(nn.Module):\n    def __init__(self, model_name):\n        super().__init__()\n        self.base_model = timm.create_model(model_name, pretrained=True, num_classes=0)\n        self.embedding_size = self.base_model.num_features\n        self.classifier = nn.Linear(self.embedding_size, 1)\n\n    def forward(self, x):\n        embeddings = self.base_model(x)\n        logits = self.classifier(embeddings)\n        return embeddings, logits\n\n    def get_embeddings(self, x):\n        \"\"\"Helper method to get only embeddings during inference\"\"\"\n        embeddings, _ = self.forward(x)\n        return embeddings\n\ndef train_embedding_model_with_hdf5(df_train, h5_path, model, output_path):\n    sample_weights = compute_class_weights(df_train, target_col='target')\n    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n\n    transforms_fn = A.Compose([\n        A.Resize(height=CNN_CONFIG[\"img_size\"], width=CNN_CONFIG[\"img_size\"]),\n        A.HorizontalFlip(),\n        A.VerticalFlip(),\n        A.Rotate(limit=180),\n        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ToTensorV2()\n    ])\n\n    train_dataset = ISICImageDatasetHDF5(h5_path, df_train, transforms=transforms_fn)\n    train_loader = DataLoader(train_dataset, batch_size=CNN_CONFIG[\"batch_size\"], \n                            sampler=sampler, num_workers=4, pin_memory=True)\n\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n    model.to(CNN_CONFIG[\"device\"])\n\n    print(\"Starting CNN embedding model training...\")\n    model.train()\n    num_epochs = 5\n    \n    # Lists to store metrics\n    train_losses = []\n    pauc_scores = []\n    \n    for epoch in range(num_epochs):\n        epoch_loss = 0\n        all_targets = []\n        all_predictions = []\n        \n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}\")\n        for imgs, targets in progress_bar:\n            imgs, targets = imgs.to(CNN_CONFIG[\"device\"]), targets.to(CNN_CONFIG[\"device\"])\n            optimizer.zero_grad()\n            \n            # Get embeddings and logits\n            embeddings, logits = model(imgs)\n            \n            # Calculate BCE loss\n            loss = criterion(logits, targets.unsqueeze(1))\n            \n            # Backward pass\n            loss.backward()\n            optimizer.step()\n            \n            # Store loss\n            epoch_loss += loss.item()\n            \n            # Store predictions and targets for pAUC calculation\n            predictions = torch.sigmoid(logits)\n            all_targets.extend(targets.cpu().numpy())\n            all_predictions.extend(predictions.detach().cpu().numpy())\n            \n            # Update progress bar\n            progress_bar.set_postfix({'Loss': f'{epoch_loss / (progress_bar.n + 1):.4f}'})\n        \n        # Calculate epoch metrics\n        avg_loss = epoch_loss / len(train_loader)\n        pauc_score = calculate_pauc(np.array(all_targets), np.array(all_predictions))\n        \n        # Store metrics\n        train_losses.append(avg_loss)\n        pauc_scores.append(pauc_score)\n        \n        print(f\"Epoch {epoch + 1} Loss: {avg_loss:.4f}, pAUC: {pauc_score:.4f}\")\n        print_gpu_memory()\n    \n    print(\"\\nTraining Summary:\")\n    print(f\"Final Loss: {train_losses[-1]:.4f}\")\n    print(f\"Final pAUC: {pauc_scores[-1]:.4f}\")\n    print(\"CNN embedding model training completed.\")\n    \n    torch.save({\n        'model_state_dict': model.state_dict(),\n        # 'train_losses': train_losses,\n        # 'pauc_scores': pauc_scores,\n    }, output_path)\n    print(f\"Model and training metrics saved to {output_path}\")\n\ndef generate_cnn_embeddings_hdf5(df, h5_path, model, output_path):\n    print(\"Generating CNN embeddings...\")\n    model.eval()\n    transforms_fn = A.Compose([\n        A.Resize(height=CNN_CONFIG[\"img_size\"], width=CNN_CONFIG[\"img_size\"]),\n        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ToTensorV2()\n    ])\n    \n    dataset = ISICImageDatasetHDF5(h5_path, df, transforms=transforms_fn)\n    dataloader = DataLoader(dataset, batch_size=CNN_CONFIG[\"batch_size\"], \n                          shuffle=False, num_workers=4, pin_memory=True)\n\n    embeddings = []\n    with torch.no_grad():\n        for imgs, _ in tqdm(dataloader, desc=\"Generating Embeddings\"):\n            imgs = imgs.to(CNN_CONFIG[\"device\"])\n            features = model.get_embeddings(imgs).cpu().numpy()\n            embeddings.append(features)\n\n    embeddings = np.vstack(embeddings)\n    embedding_df = pd.DataFrame(embeddings, index=df['isic_id'])\n    embedding_df.to_csv(output_path)\n    print(\"CNN embeddings generated.\")\n    print(f\"Embeddings saved to {output_path}\")\n\ndef compute_class_weights(df, target_col):\n    class_counts = df[target_col].value_counts().to_dict()\n    total_samples = len(df)\n    weights = {cls: total_samples / count for cls, count in class_counts.items()}\n    sample_weights = df[target_col].map(weights).values\n    return sample_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T02:51:07.580979Z","iopub.execute_input":"2024-12-09T02:51:07.581304Z","iopub.status.idle":"2024-12-09T02:51:07.604473Z","shell.execute_reply.started":"2024-12-09T02:51:07.581280Z","shell.execute_reply":"2024-12-09T02:51:07.603802Z"}},"outputs":[],"execution_count":149},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    print(\"Loading training data...\")\n    \n    RANDOM_SEED = 42\n    train_h5 = root / 'train-image.hdf5'\n    cnn_model_path = 'cnn_model_hdf5_balanced.pth'\n\n    cat_cols = ['sex', 'anatom_site_general', 'tbp_lv_location', 'tbp_lv_location_simple']\n    \n    df_train = read_data(train_path)\n    df_competition_test = read_data(test_path)\n    df_subm = pd.read_csv(subm_path, index_col=id_col)\n\n    df_train = df_train.reset_index()  # Ensures isic_id is now a column\n    df_competition_test = df_competition_test.reset_index()\n    \n    # Preprocess now returns df_train, df_competition_test, cat_cols, new_feature_cols\n    df_train, df_competition_test, cat_cols, new_feature_cols = preprocess(df_train, df_competition_test, cat_cols, new_feature_cols)\n\n    # Create a holdout test set\n    df_positive = df_train[df_train['target'] == 1]\n    df_negative = df_train[df_train['target'] == 0]\n\n    test_pos_size = int(0.1 * len(df_positive))\n    df_test_positive = df_positive.sample(n=test_pos_size, random_state=RANDOM_SEED)\n    df_train_positive = df_positive.drop(df_test_positive.index)\n\n    df_test_negative = df_negative.sample(n=test_pos_size, random_state=RANDOM_SEED)\n    df_train_negative = df_negative.drop(df_test_negative.index)\n\n    # df_test = pd.concat([df_test_positive, df_test_negative], ignore_index=True).sample(frac=1, random_state=RANDOM_SEED)\n    # df_train = pd.concat([df_train_positive, df_train_negative], ignore_index=True).sample(frac=1, random_state=RANDOM_SEED)\n    df_test = pd.concat([df_test_positive, df_test_negative]).sample(frac=1, random_state=RANDOM_SEED)\n    df_train = pd.concat([df_train_positive, df_train_negative]).sample(frac=1, random_state=RANDOM_SEED)\n\n    df_test = df_test.reset_index().rename(columns={'index': 'isic_id'})\n\n    # Create balanced subset for CNN training\n    total_size = 10000\n    df_positive = df_train[df_train['target'] == 1]\n    df_negative = df_train[df_train['target'] == 0]\n    pos_count = len(df_positive)\n    neg_count = total_size - pos_count\n\n    df_negative_sampled = df_negative.sample(n=neg_count, random_state=RANDOM_SEED)\n    df_small = pd.concat([df_positive, df_negative_sampled], axis=0).sample(frac=1, random_state=RANDOM_SEED)\n\n    # df_small_for_cnn = df_small.copy()\n    df_small_for_cnn = df_small.reset_index()\n    # df_small = df_small.set_index('isic_id')\n\n    print(\"Initializing CNN embedding model...\")\n    embedding_model = EmbeddingModel(CNN_CONFIG[\"pretrained_model\"])\n\n    train_embedding_model_with_hdf5(df_small_for_cnn, train_h5, embedding_model, cnn_model_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T06:07:49.095682Z","iopub.status.idle":"2024-12-09T06:07:49.096146Z","shell.execute_reply.started":"2024-12-09T06:07:49.095916Z","shell.execute_reply":"2024-12-09T06:07:49.095936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df_test.columns)  \n# should show 'isic_id' as a column now","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Use embeddings to retrain model","metadata":{}},{"cell_type":"code","source":"def custom_cross_val(estimator, X, y, cv, groups):\n    importances = []\n    scores = []\n    splits = list(cv.split(X, y, groups))\n    \n    # Progress bar for folds\n    fold_iterator = tqdm(enumerate(splits), \n                        total=5, \n                        desc=\"Folds\",\n                        position=0)\n    \n    for fold_idx, (train_idx, val_idx) in fold_iterator:\n        fold_start_time = time.time()\n        \n        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n        \n        # Fit the model\n        estimator.fit(X_train, y_train)\n        \n        # Get scores\n        score = custom_metric(estimator, X_val, y_val)\n        scores.append(score)\n        \n        # Extract and store feature importances from each LightGBM model\n        # Initialize with correct shape\n        fold_importance = np.zeros(X.shape[1])\n        \n        for name, pipeline in estimator.named_estimators_.items(): \n            lgb_model = pipeline.named_steps['classifier']\n            # Make sure feature importances match the number of features\n            if len(lgb_model.feature_importances_) != X.shape[1]:\n                continue  # Skip if shapes don't match\n            fold_importance += lgb_model.feature_importances_\n        \n        importances.append(fold_importance / len(estimator.named_estimators_))\n        \n        fold_time = time.time() - fold_start_time\n        print(f\"Fold {fold_idx + 1} completed in {fold_time:.2f} seconds\")\n        \n        # Update fold progress bar with timing info\n        fold_iterator.set_postfix({'Score': f'{score:.4f}'})\n    \n    print('\\n')\n    return np.array(scores), np.array(importances)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T04:32:12.072105Z","iopub.execute_input":"2024-12-09T04:32:12.072744Z","iopub.status.idle":"2024-12-09T04:32:12.080331Z","shell.execute_reply.started":"2024-12-09T04:32:12.072714Z","shell.execute_reply":"2024-12-09T04:32:12.079477Z"}},"outputs":[],"execution_count":199},{"cell_type":"code","source":"print(\"\\nBefore embedding generation:\")\nprint(\"Sample of isic_ids:\", df_small_for_cnn['isic_id'].head())\nprint(\"Sample of df_small index:\", df_small.index[:5])\n\n# Generate embeddings using df_small_for_cnn\nprint(\"\\nGenerating embeddings...\")\ngenerate_cnn_embeddings_hdf5(df_small_for_cnn, train_h5, embedding_model, \"train_embeddings.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T05:02:33.786281Z","iopub.execute_input":"2024-12-09T05:02:33.786977Z","iopub.status.idle":"2024-12-09T05:05:42.944843Z","shell.execute_reply.started":"2024-12-09T05:02:33.786943Z","shell.execute_reply":"2024-12-09T05:05:42.943758Z"}},"outputs":[{"name":"stdout","text":"\nBefore embedding generation:\nSample of isic_ids: 0    ISIC_3671934\n1    ISIC_9529247\n2    ISIC_4551312\n3    ISIC_5323671\n4    ISIC_2563670\nName: isic_id, dtype: object\nSample of df_small index: Index(['ISIC_3671934', 'ISIC_9529247', 'ISIC_4551312', 'ISIC_5323671',\n       'ISIC_2563670'],\n      dtype='object', name='isic_id')\n\nGenerating embeddings...\nGenerating CNN embeddings...\n","output_type":"stream"},{"name":"stderr","text":"Generating Embeddings: 100%|██████████| 313/313 [02:57<00:00,  1.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"CNN embeddings generated.\nEmbeddings saved to train_embeddings.csv\n","output_type":"stream"}],"execution_count":209},{"cell_type":"code","source":"# Load embeddings\nembedding_df = pd.read_csv(\"train_embeddings.csv\", index_col='isic_id')\n\n# Verify matching\nprint(\"\\nVerification after embedding generation:\")\nprint(\"Sample of embedding_df index:\", embedding_df.index[:5])\nprint(f\"df_small shape: {df_small.shape}\")\nprint(f\"embedding_df shape: {embedding_df.shape}\")\nprint(f\"Number of overlapping indices: {len(set(df_small.index).intersection(set(embedding_df.index)))}\")\n\nfor col in df_small.select_dtypes(include=['category']).columns:\n    df_small[col] = df_small[col].cat.codes\n\n# Debug column names\nprint(\"\\nChecking for duplicate columns:\")\nprint(\"Feature columns:\", len(new_feature_cols), len(set(new_feature_cols)))\nduplicates = [x for x in new_feature_cols if new_feature_cols.count(x) > 1]\nprint(\"Duplicate features:\", duplicates)\n\nunique_feature_cols = list(dict.fromkeys(new_feature_cols))\n\n# Make sure all columns are unique before concatenation\nX_with_embeddings = pd.concat([\n    df_small[new_feature_cols].loc[:,~df_small[new_feature_cols].columns.duplicated()],  # Remove duplicates\n    embedding_df\n], axis=1)\n\n# Update feature columns list to include embeddings\nnew_feature_cols_with_emb = unique_feature_cols + [f'emb_{i}' for i in range(embedding_df.shape[1])]\n\n\nprint(\"Final column check:\")\nprint(\"Total columns:\", X_with_embeddings.shape[1])\nprint(\"Unique columns:\", len(X_with_embeddings.columns.unique()))\n\ny = df_small[target_col]\ngroups = df_small[group_col]\n\nprint(\"\\nFinal dataset shapes:\")\nprint(f\"X_with_embeddings shape: {X_with_embeddings.shape}\")\nprint(f\"y shape: {y.shape}\")\nprint(f\"groups shape: {groups.shape}\")\n\n# # Convert categorical columns to string type\n# categorical_columns = X_with_embeddings.select_dtypes(include=['category']).columns\n# for col in categorical_columns:\n#     X_with_embeddings[col] = X_with_embeddings[col].astype(str)\n\n\n\nif len(X_with_embeddings) > 0:\n    print(\"\\nProceeding with model training...\")\n\n    # Modified LightGBM parameters\n    lgb_params_updated = lgb_params.copy()\n    lgb_params_updated.update({\n        'categorical_feature': None,\n        'verbose': -1\n    })\n    \n    # Create CV splitter\n    cv = StratifiedGroupKFold(5, shuffle=True, random_state=seed)\n    \n    # Create estimator for balanced data\n    estimator_balanced = VotingClassifier([\n        ('lgb1', Pipeline([\n            ('sampler', RandomUnderSampler(sampling_strategy=1, random_state=12)),\n            ('classifier', lgb.LGBMClassifier(**lgb_params_updated, random_state=12)),\n        ])),\n        ('lgb2', Pipeline([\n            ('sampler', RandomUnderSampler(sampling_strategy=1, random_state=22)),\n            ('classifier', lgb.LGBMClassifier(**lgb_params_updated, random_state=22)),\n        ])),\n        ('lgb3', Pipeline([\n            ('sampler', RandomUnderSampler(sampling_strategy=1, random_state=32)),\n            ('classifier', lgb.LGBMClassifier(**lgb_params_updated, random_state=32)),\n        ])),\n        ('lgb4', Pipeline([\n            ('sampler', RandomUnderSampler(sampling_strategy=1, random_state=42)),\n            ('classifier', lgb.LGBMClassifier(**lgb_params_updated, random_state=42)),\n        ])),\n        ('lgb5', Pipeline([\n            ('sampler', RandomUnderSampler(sampling_strategy=1, random_state=52)),\n            ('classifier', lgb.LGBMClassifier(**lgb_params_updated, random_state=52)),\n        ])),\n    ], voting='soft')\n    \n    # Run cross-validation\n    print(\"\\nStarting cross-validation with embeddings...\")\n    scores, all_fold_importances = custom_cross_val(\n        estimator=estimator_balanced,\n        X=X_with_embeddings, \n        y=y,\n        cv=cv,\n        groups=groups\n    )\n    \n    # Print results\n    print(\"\\nTraining Complete with Embeddings!\")\n    print(f\"Mean score: {np.mean(scores):.4f}\")\n    print(f\"Score std: {np.std(scores):.4f}\")\n    print(f\"All scores: {scores}\")\n    \n    # Compute feature importance\n    mean_importances = all_fold_importances.mean(axis=0)\n    importance_df = pd.DataFrame({\n        'feature': new_feature_cols_with_emb,\n        'importance': mean_importances\n    }).sort_values('importance', ascending=False)\n    \n    print(\"\\nTop 50 Most Important Features (with Embeddings):\")\n    print(importance_df.head(50))\n    \n    # Train final model\n    estimator_balanced.fit(X_with_embeddings, y)\n    \n    # Save model\n    with open('hybrid_model.pkl', 'wb') as file:\n        pickle.dump(estimator_balanced, file)\n\nelse:\n    raise ValueError(\"No data after joining features with embeddings. Check index alignment.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T05:08:52.089474Z","iopub.execute_input":"2024-12-09T05:08:52.090239Z","iopub.status.idle":"2024-12-09T05:09:49.888239Z","shell.execute_reply.started":"2024-12-09T05:08:52.090214Z","shell.execute_reply":"2024-12-09T05:09:49.887298Z"}},"outputs":[{"name":"stdout","text":"\nVerification after embedding generation:\nSample of embedding_df index: Index(['ISIC_3671934', 'ISIC_9529247', 'ISIC_4551312', 'ISIC_5323671',\n       'ISIC_2563670'],\n      dtype='object', name='isic_id')\ndf_small shape: (10000, 109)\nembedding_df shape: (10000, 1280)\nNumber of overlapping indices: 10000\n\nChecking for duplicate columns:\nFeature columns: 228 76\nDuplicate features: ['onehot_0', 'onehot_1', 'onehot_2', 'onehot_3', 'onehot_4', 'onehot_5', 'onehot_6', 'onehot_7', 'onehot_8', 'onehot_9', 'onehot_10', 'onehot_11', 'onehot_12', 'onehot_13', 'onehot_14', 'onehot_15', 'onehot_16', 'onehot_17', 'onehot_18', 'onehot_19', 'onehot_20', 'onehot_21', 'onehot_22', 'onehot_23', 'onehot_24', 'onehot_25', 'onehot_26', 'onehot_27', 'onehot_28', 'onehot_29', 'onehot_30', 'onehot_31', 'onehot_32', 'onehot_33', 'onehot_34', 'onehot_35', 'onehot_36', 'onehot_37', 'onehot_0', 'onehot_1', 'onehot_2', 'onehot_3', 'onehot_4', 'onehot_5', 'onehot_6', 'onehot_7', 'onehot_8', 'onehot_9', 'onehot_10', 'onehot_11', 'onehot_12', 'onehot_13', 'onehot_14', 'onehot_15', 'onehot_16', 'onehot_17', 'onehot_18', 'onehot_19', 'onehot_20', 'onehot_21', 'onehot_22', 'onehot_23', 'onehot_24', 'onehot_25', 'onehot_26', 'onehot_27', 'onehot_28', 'onehot_29', 'onehot_30', 'onehot_31', 'onehot_32', 'onehot_33', 'onehot_34', 'onehot_35', 'onehot_36', 'onehot_37', 'onehot_0', 'onehot_1', 'onehot_2', 'onehot_3', 'onehot_4', 'onehot_5', 'onehot_6', 'onehot_7', 'onehot_8', 'onehot_9', 'onehot_10', 'onehot_11', 'onehot_12', 'onehot_13', 'onehot_14', 'onehot_15', 'onehot_16', 'onehot_17', 'onehot_18', 'onehot_19', 'onehot_20', 'onehot_21', 'onehot_22', 'onehot_23', 'onehot_24', 'onehot_25', 'onehot_26', 'onehot_27', 'onehot_28', 'onehot_29', 'onehot_30', 'onehot_31', 'onehot_32', 'onehot_33', 'onehot_34', 'onehot_35', 'onehot_36', 'onehot_37', 'onehot_0', 'onehot_1', 'onehot_2', 'onehot_3', 'onehot_4', 'onehot_5', 'onehot_6', 'onehot_7', 'onehot_8', 'onehot_9', 'onehot_10', 'onehot_11', 'onehot_12', 'onehot_13', 'onehot_14', 'onehot_15', 'onehot_16', 'onehot_17', 'onehot_18', 'onehot_19', 'onehot_20', 'onehot_21', 'onehot_22', 'onehot_23', 'onehot_24', 'onehot_25', 'onehot_26', 'onehot_27', 'onehot_28', 'onehot_29', 'onehot_30', 'onehot_31', 'onehot_32', 'onehot_33', 'onehot_34', 'onehot_35', 'onehot_36', 'onehot_37', 'onehot_0', 'onehot_1', 'onehot_2', 'onehot_3', 'onehot_4', 'onehot_5', 'onehot_6', 'onehot_7', 'onehot_8', 'onehot_9', 'onehot_10', 'onehot_11', 'onehot_12', 'onehot_13', 'onehot_14', 'onehot_15', 'onehot_16', 'onehot_17', 'onehot_18', 'onehot_19', 'onehot_20', 'onehot_21', 'onehot_22', 'onehot_23', 'onehot_24', 'onehot_25', 'onehot_26', 'onehot_27', 'onehot_28', 'onehot_29', 'onehot_30', 'onehot_31', 'onehot_32', 'onehot_33', 'onehot_34', 'onehot_35', 'onehot_36', 'onehot_37']\nFinal column check:\nTotal columns: 1356\nUnique columns: 1356\n\nFinal dataset shapes:\nX_with_embeddings shape: (10000, 1356)\ny shape: (10000,)\ngroups shape: (10000,)\n\nProceeding with model training...\n\nStarting cross-validation with embeddings...\n","output_type":"stream"},{"name":"stderr","text":"Folds:  20%|██        | 1/5 [00:08<00:33,  8.42s/it, Score=0.1998]","output_type":"stream"},{"name":"stdout","text":"Fold 1 completed in 8.42 seconds\n","output_type":"stream"},{"name":"stderr","text":"Folds:  40%|████      | 2/5 [00:17<00:25,  8.51s/it, Score=0.1994]","output_type":"stream"},{"name":"stdout","text":"Fold 2 completed in 8.58 seconds\n","output_type":"stream"},{"name":"stderr","text":"Folds:  60%|██████    | 3/5 [00:26<00:17,  8.81s/it, Score=0.1996]","output_type":"stream"},{"name":"stdout","text":"Fold 3 completed in 9.17 seconds\n","output_type":"stream"},{"name":"stderr","text":"Folds:  80%|████████  | 4/5 [00:35<00:09,  9.04s/it, Score=0.1994]","output_type":"stream"},{"name":"stdout","text":"Fold 4 completed in 9.37 seconds\n","output_type":"stream"},{"name":"stderr","text":"Folds: 100%|██████████| 5/5 [00:44<00:00,  8.95s/it, Score=0.1995]","output_type":"stream"},{"name":"stdout","text":"Fold 5 completed in 9.20 seconds\n\n\n\nTraining Complete with Embeddings!\nMean score: 0.1996\nScore std: 0.0001\nAll scores: [0.19981785 0.1994102  0.19962518 0.19942158 0.19954706]\n\nTop 50 Most Important Features (with Embeddings):\n       feature  importance\n887    emb_811       14.12\n644    emb_568       12.04\n310    emb_234       11.12\n124     emb_48       10.88\n853    emb_777       10.40\n143     emb_67        9.52\n1128  emb_1052        8.24\n408    emb_332        7.60\n1119  emb_1043        7.60\n364    emb_288        7.44\n610    emb_534        7.28\n1193  emb_1117        6.80\n1108  emb_1032        6.80\n844    emb_768        6.08\n446    emb_370        5.52\n755    emb_679        5.40\n1283  emb_1207        5.36\n475    emb_399        5.32\n885    emb_809        5.08\n289    emb_213        5.04\n1223  emb_1147        5.00\n612    emb_536        4.92\n288    emb_212        4.68\n1292  emb_1216        4.24\n697    emb_621        4.24\n1135  emb_1059        4.04\n1163  emb_1087        3.88\n655    emb_579        3.64\n153     emb_77        3.56\n796    emb_720        3.52\n804    emb_728        3.28\n1020   emb_944        3.24\n901    emb_825        3.20\n1212  emb_1136        3.20\n963    emb_887        2.96\n662    emb_586        2.96\n299    emb_223        2.88\n235    emb_159        2.84\n561    emb_485        2.84\n1349  emb_1273        2.76\n777    emb_701        2.52\n526    emb_450        2.48\n284    emb_208        2.44\n493    emb_417        2.44\n972    emb_896        2.44\n868    emb_792        2.40\n320    emb_244        2.32\n1142  emb_1066        2.28\n565    emb_489        2.28\n820    emb_744        2.28\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":211},{"cell_type":"markdown","source":"# Compare two models on holdout test set","metadata":{}},{"cell_type":"code","source":"df_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T06:00:48.682105Z","iopub.execute_input":"2024-12-09T06:00:48.682395Z","iopub.status.idle":"2024-12-09T06:00:48.708555Z","shell.execute_reply.started":"2024-12-09T06:00:48.682372Z","shell.execute_reply":"2024-12-09T06:00:48.707695Z"}},"outputs":[{"execution_count":241,"output_type":"execute_result","data":{"text/plain":"    target  patient_id  age_approx     sex anatom_site_general  \\\n33       1  IP_2945977        55.0  female      anterior torso   \n0        1  IP_2456971        60.0    male           head/neck   \n34       1  IP_3028432        65.0    male     lower extremity   \n12       1  IP_7797815        75.0    male     upper extremity   \n10       1  IP_7411721        45.0    male     posterior torso   \n..     ...         ...         ...     ...                 ...   \n20       1  IP_4513696        45.0  female     posterior torso   \n60       0  IP_2945977        55.0  female     posterior torso   \n71       0  IP_4304202        55.0    male     posterior torso   \n14       1  IP_0152575        60.0  female      anterior torso   \n51       0  IP_1092190        65.0  female     lower extremity   \n\n    clin_size_long_diam_mm          image_type tbp_tile_type   tbp_lv_A  \\\n33                    7.48  TBP tile: close-up        3D: XP  25.711526   \n0                     2.70  TBP tile: close-up     3D: white  26.867286   \n34                    5.01  TBP tile: close-up     3D: white  20.284447   \n12                    1.23  TBP tile: close-up     3D: white  11.869290   \n10                    5.62  TBP tile: close-up        3D: XP  23.281400   \n..                     ...                 ...           ...        ...   \n20                    1.23  TBP tile: close-up        3D: XP  16.429892   \n60                    4.17  TBP tile: close-up        3D: XP  18.997522   \n71                    2.32  TBP tile: close-up        3D: XP  23.344960   \n14                    5.27  TBP tile: close-up        3D: XP  15.614144   \n51                    2.65  TBP tile: close-up        3D: XP  23.710909   \n\n    tbp_lv_Aext  ...  onehot_28  onehot_29  onehot_30  onehot_31  onehot_32  \\\n33    17.473305  ...          1          0          0          0          0   \n0     20.574389  ...          0          0          1          0          0   \n34    15.174651  ...          0          0          0          0          1   \n12     8.123813  ...          0          0          0          0          0   \n10    15.250300  ...          0          0          0          0          0   \n..          ...  ...        ...        ...        ...        ...        ...   \n20    13.567763  ...          0          0          0          0          0   \n60    14.310354  ...          0          0          0          0          0   \n71    16.223478  ...          0          0          0          0          0   \n14    15.523538  ...          1          0          0          0          0   \n51    16.222617  ...          0          0          0          0          1   \n\n    onehot_33  onehot_34  onehot_35  onehot_36  onehot_37  \n33          0          0          0          1          0  \n0           0          0          0          0          0  \n34          0          0          0          0          0  \n12          1          0          0          0          0  \n10          0          0          1          0          0  \n..        ...        ...        ...        ...        ...  \n20          0          0          1          0          0  \n60          0          0          1          0          0  \n71          0          0          1          0          0  \n14          0          0          0          1          0  \n51          0          0          0          0          0  \n\n[78 rows x 109 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>patient_id</th>\n      <th>age_approx</th>\n      <th>sex</th>\n      <th>anatom_site_general</th>\n      <th>clin_size_long_diam_mm</th>\n      <th>image_type</th>\n      <th>tbp_tile_type</th>\n      <th>tbp_lv_A</th>\n      <th>tbp_lv_Aext</th>\n      <th>...</th>\n      <th>onehot_28</th>\n      <th>onehot_29</th>\n      <th>onehot_30</th>\n      <th>onehot_31</th>\n      <th>onehot_32</th>\n      <th>onehot_33</th>\n      <th>onehot_34</th>\n      <th>onehot_35</th>\n      <th>onehot_36</th>\n      <th>onehot_37</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>33</th>\n      <td>1</td>\n      <td>IP_2945977</td>\n      <td>55.0</td>\n      <td>female</td>\n      <td>anterior torso</td>\n      <td>7.48</td>\n      <td>TBP tile: close-up</td>\n      <td>3D: XP</td>\n      <td>25.711526</td>\n      <td>17.473305</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>IP_2456971</td>\n      <td>60.0</td>\n      <td>male</td>\n      <td>head/neck</td>\n      <td>2.70</td>\n      <td>TBP tile: close-up</td>\n      <td>3D: white</td>\n      <td>26.867286</td>\n      <td>20.574389</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>1</td>\n      <td>IP_3028432</td>\n      <td>65.0</td>\n      <td>male</td>\n      <td>lower extremity</td>\n      <td>5.01</td>\n      <td>TBP tile: close-up</td>\n      <td>3D: white</td>\n      <td>20.284447</td>\n      <td>15.174651</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1</td>\n      <td>IP_7797815</td>\n      <td>75.0</td>\n      <td>male</td>\n      <td>upper extremity</td>\n      <td>1.23</td>\n      <td>TBP tile: close-up</td>\n      <td>3D: white</td>\n      <td>11.869290</td>\n      <td>8.123813</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>IP_7411721</td>\n      <td>45.0</td>\n      <td>male</td>\n      <td>posterior torso</td>\n      <td>5.62</td>\n      <td>TBP tile: close-up</td>\n      <td>3D: XP</td>\n      <td>23.281400</td>\n      <td>15.250300</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>1</td>\n      <td>IP_4513696</td>\n      <td>45.0</td>\n      <td>female</td>\n      <td>posterior torso</td>\n      <td>1.23</td>\n      <td>TBP tile: close-up</td>\n      <td>3D: XP</td>\n      <td>16.429892</td>\n      <td>13.567763</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>0</td>\n      <td>IP_2945977</td>\n      <td>55.0</td>\n      <td>female</td>\n      <td>posterior torso</td>\n      <td>4.17</td>\n      <td>TBP tile: close-up</td>\n      <td>3D: XP</td>\n      <td>18.997522</td>\n      <td>14.310354</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>0</td>\n      <td>IP_4304202</td>\n      <td>55.0</td>\n      <td>male</td>\n      <td>posterior torso</td>\n      <td>2.32</td>\n      <td>TBP tile: close-up</td>\n      <td>3D: XP</td>\n      <td>23.344960</td>\n      <td>16.223478</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1</td>\n      <td>IP_0152575</td>\n      <td>60.0</td>\n      <td>female</td>\n      <td>anterior torso</td>\n      <td>5.27</td>\n      <td>TBP tile: close-up</td>\n      <td>3D: XP</td>\n      <td>15.614144</td>\n      <td>15.523538</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>0</td>\n      <td>IP_1092190</td>\n      <td>65.0</td>\n      <td>female</td>\n      <td>lower extremity</td>\n      <td>2.65</td>\n      <td>TBP tile: close-up</td>\n      <td>3D: XP</td>\n      <td>23.710909</td>\n      <td>16.222617</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>78 rows × 109 columns</p>\n</div>"},"metadata":{}}],"execution_count":241},{"cell_type":"code","source":"def custom_pauc(y_true, y_pred, min_tpr=0.80):\n    max_fpr = abs(1 - min_tpr)\n    v_gt = abs(y_true - 1)\n    v_pred = 1.0 - y_pred\n    \n    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n    return partial_auc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T06:11:59.500206Z","iopub.execute_input":"2024-12-09T06:11:59.501056Z","iopub.status.idle":"2024-12-09T06:11:59.505743Z","shell.execute_reply.started":"2024-12-09T06:11:59.501026Z","shell.execute_reply":"2024-12-09T06:11:59.504820Z"}},"outputs":[],"execution_count":251},{"cell_type":"code","source":"X_test = df_test[unique_feature_cols]\ny_test = df_test[target_col]\n\nwith open('model.pkl', 'rb') as f:\n    estimator = pickle.load(f)\n\ny_pred_estimator = estimator.predict_proba(X_test)[:, 1]\n\n# Compute partial AUC\nauc_estimator = custom_pauc(y_test, y_pred_estimator)\n\nprint(f\"AUC for the tabular model: {auc_estimator:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T06:11:59.665961Z","iopub.execute_input":"2024-12-09T06:11:59.666197Z","iopub.status.idle":"2024-12-09T06:11:59.758524Z","shell.execute_reply.started":"2024-12-09T06:11:59.666177Z","shell.execute_reply":"2024-12-09T06:11:59.757527Z"}},"outputs":[{"name":"stdout","text":"AUC for the tabular model: 0.1648\n","output_type":"stream"}],"execution_count":252},{"cell_type":"markdown","source":"# Compute pAUC on holdout test set for Hybrid model (too many bugs :( )","metadata":{}},{"cell_type":"code","source":"# # For the first model (tabular only)\n# X_test = df_test[unique_feature_cols]  # Use the deduplicated columns\n# y_test = df_test[target_col]\n\n# # # For the second model (hybrid)\n# # # First generate embeddings for test set\n# # test_cnn = df_test.reset_index().rename(columns={'index': 'isic_id'})\n# # test_cnn['isic_id'] = test_cnn['isic_id'].astype(str)\n# # generate_cnn_embeddings_hdf5(test_cnn, train_h5, embedding_model, \"test_embeddings.csv\")\n# # test_embeddings = pd.read_csv(\"test_embeddings.csv\", index_col='isic_id')\n\n# # # Combine features with embeddings for test set\n# # X_test_hybrid = pd.concat([\n# #     df_test[unique_feature_cols],\n# #     test_embeddings\n# # ], axis=1)\n\n# # # Get predictions from the hybrid model\n# # y_pred_estimator_balanced = estimator_balanced.predict_proba(X_test_hybrid)[:, 1]\n# # # Evaluate (e.g. AUC)\n# # auc_estimator_balanced = roc_auc_score(y_test, y_pred_estimator_balanced)\n\n# # print(f\"AUC for the hybrid model: {auc_estimator_balanced:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T06:13:28.038598Z","iopub.execute_input":"2024-12-09T06:13:28.039159Z","iopub.status.idle":"2024-12-09T06:13:28.043506Z","shell.execute_reply.started":"2024-12-09T06:13:28.039131Z","shell.execute_reply":"2024-12-09T06:13:28.042640Z"}},"outputs":[],"execution_count":254}]}