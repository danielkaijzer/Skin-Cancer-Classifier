{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook I create two models:\n",
    "- A tabular only model that is intended to be used to predict target based on only user input and the features generated by my image_feature_extractor.py program (uses OpenCV to extract geometric and color features from image directly).\n",
    "- A hybrid model that combines my tabular model with a CNN by concatinating CNN feature embeddings with tabular data to retrain the tabular model.\n",
    "\n",
    "Inspiration for tabular model used in this notebook: https://www.kaggle.com/code/greysky/isic-2024-only-tabular-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:16:31.782076Z",
     "iopub.status.busy": "2024-12-12T22:16:31.781609Z",
     "iopub.status.idle": "2024-12-12T22:16:31.789191Z",
     "shell.execute_reply": "2024-12-12T22:16:31.788225Z",
     "shell.execute_reply.started": "2024-12-12T22:16:31.782046Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pickle\n",
    "import json\n",
    "from io import BytesIO\n",
    "import timm\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "import lightgbm as lgb\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:16:32.133863Z",
     "iopub.status.busy": "2024-12-12T22:16:32.132959Z",
     "iopub.status.idle": "2024-12-12T22:16:32.140175Z",
     "shell.execute_reply": "2024-12-12T22:16:32.138851Z",
     "shell.execute_reply.started": "2024-12-12T22:16:32.133809Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "root = Path('/kaggle/input/isic-2024-challenge')\n",
    "train_path = root / 'train-metadata.csv'\n",
    "test_path = root / 'test-metadata.csv'\n",
    "subm_path = root / 'sample_submission.csv'\n",
    "\n",
    "id_col = 'isic_id'\n",
    "target_col = 'target'\n",
    "group_col = 'patient_id'\n",
    "\n",
    "err = 1e-5\n",
    "sampling_ratio = 0.5 # previously was 0.01\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:16:32.766405Z",
     "iopub.status.busy": "2024-12-12T22:16:32.766086Z",
     "iopub.status.idle": "2024-12-12T22:16:32.775796Z",
     "shell.execute_reply": "2024-12-12T22:16:32.774914Z",
     "shell.execute_reply.started": "2024-12-12T22:16:32.766382Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "user_input_features_num = [\n",
    "    # User Input Features\n",
    "    'age_approx',                  # Ask user for age\n",
    "    'sex',                         # Ask user for sex\n",
    "    'anatom_site_general',         # Ask user to put in anatomical site (from list of options)\n",
    "    'clin_size_long_diam_mm',      # Ask user for size of lesion in mm\n",
    "    'tbp_lv_location',\t           # Classification of anatomical location, divides arms & legs to upper & lower; torso into thirds.+\n",
    "    'tbp_lv_location_simple',\t   # Classification of anatomical location, simple.+\n",
    "]\n",
    "\n",
    "cv_features = [\n",
    "    # Shape\n",
    "    'tbp_lv_areaMM2',                    # Area of lesion (mm^2).+\n",
    "    'tbp_lv_perimeterMM',                # Perimeter of lesion (mm).+\n",
    "\n",
    "    'tbp_lv_minorAxisMM',\t             # Smallest lesion diameter (mm).+ AXIS OF LEAST SECOND MOMENT!\n",
    "    'tbp_lv_eccentricity',               # Eccentricity. (use min_inertia line and max_inertia line)\n",
    "    'tbp_lv_area_perim_ratio',           # Border jaggedness, the ratio between lesions perimeter and area. Circular lesions will have low values; irregular shaped lesions will have higher values. Values range 0-10.+\n",
    "    \n",
    "    # Color Features\n",
    "    'tbp_lv_A',\t                         # A inside lesion.+\n",
    "    'tbp_lv_Aext',\t                     # A outside lesion.+\n",
    "    'tbp_lv_B',                          # B inside lesion.+\n",
    "    'tbp_lv_Bext',                       # B outside lesion.+\n",
    "    'tbp_lv_C',                          # Chroma inside  lesion.+\n",
    "    'tbp_lv_Cext',                       # Chroma outside lesion.+\n",
    "    'tbp_lv_H',                          # Hue inside the lesion; calculated as the angle of A* and B* in LAB* color space. Typical values range from 25 (red) to 75 (brown).+\n",
    "    'tbp_lv_Hext',                       # Hue outside lesion.+\n",
    "    'tbp_lv_L',                          # L inside lesion.+\n",
    "    'tbp_lv_Lext',                       # L outside lesion.+\n",
    "    \n",
    "    'tbp_lv_deltaA',\t           # Average A contrast (inside vs. outside lesion).+\n",
    "    'tbp_lv_deltaB',               # Color difference\n",
    "    'tbp_lv_deltaL',\t           # Average L contrast (inside vs. outside lesion).+\n",
    "    # 'tbp_lv_stdL',\t               # Standard deviation of L inside lesion.+\n",
    "    # 'tbp_lv_stdLExt',\t           # Standard deviation of L outside lesion.+\n",
    "    'tbp_lv_deltaLBnorm',          # Contrast between the lesion and its immediate surrounding skin. Low contrast lesions tend to be faintly visible such as freckles; high contrast lesions tend to be those with darker pigment. Calculated as the average delta LB of the lesion relative to its immediate background in LAB* color space. Typical values range from 5.5 to 25.+\n",
    "    # 'tbp_lv_color_std_mean',\t   # Color irregularity, calculated as the variance of colors within the lesion's boundary.\n",
    "\n",
    "    # Harder to implement\n",
    "    # 'tbp_lv_radial_color_std_max',\t     # Color asymmetry, a measure of asymmetry of the spatial distribution of color within the lesion. This score is calculated by looking at the average standard deviation in LAB* color space within concentric rings originating from the lesion center. Values range 0-10.+\n",
    "    # 'tbp_lv_symm_2axis',\t             # Border asymmetry; a measure of asymmetry of the lesion's contour about an axis perpendicular to the lesion's most symmetric axis. Lesions with two axes of symmetry will therefore have low scores (more symmetric), while lesions with only one or zero axes of symmetry will have higher scores (less symmetric). This score is calculated by comparing opposite halves of the lesion contour over many degrees of rotation. The angle where the halves are most similar identifies the principal axis of symmetry, while the second axis of symmetry is perpendicular to the principal axis. Border asymmetry is reported as the asymmetry value about this second axis. Values range 0-10.+\n",
    "    # 'tbp_lv_symm_2axis_angle',\t         # Lesion border asymmetry angle.+\n",
    "    # 'tbp_lv_norm_border',\t       # Border irregularity (0-10 scale); the normalized average of border jaggedness and asymmetry.+\n",
    "    # 'tbp_lv_norm_color',\t       # Color variation (0-10 scale); the normalized average of color asymmetry and color irregularity.+\n",
    "\n",
    "    \n",
    "]\n",
    "\n",
    "derived_features = [\n",
    "    'lesion_size_ratio',             # tbp_lv_minorAxisMM      / clin_size_long_diam_mm\n",
    "    'lesion_shape_index',            # tbp_lv_areaMM2          / tbp_lv_perimeterMM **2\n",
    "    'hue_contrast',                  # tbp_lv_H                - tbp_lv_Hext              abs\n",
    "    'luminance_contrast',            # tbp_lv_L                - tbp_lv_Lext              abs\n",
    "    'lesion_color_difference',       # tbp_lv_deltaA **2       + tbp_lv_deltaB **2 + tbp_lv_deltaL **2  sqrt  \n",
    "    'perimeter_to_area_ratio',       # tbp_lv_perimeterMM      / tbp_lv_areaMM2\n",
    "    'area_to_perimeter_ratio',       # tbp_lv_areaMM2          / tbp_lv_perimeterMM\n",
    "    # 'color_consistency',             # tbp_lv_stdL             / tbp_lv_Lext\n",
    "    # 'consistency_color',             # tbp_lv_stdL*tbp_lv_Lext / tbp_lv_stdL + tbp_lv_Lext\n",
    "    'size_age_interaction',          # clin_size_long_diam_mm  * age_approx\n",
    "    # 'hue_color_std_interaction',     # tbp_lv_H                * tbp_lv_color_std_mean\n",
    "    'color_contrast_index',          # tbp_lv_deltaA + tbp_lv_deltaB + tbp_lv_deltaL + tbp_lv_deltaLBnorm\n",
    "    'log_lesion_area',               # tbp_lv_areaMM2          + 1  np.log\n",
    "    'normalized_lesion_size',        # clin_size_long_diam_mm  / age_approx\n",
    "    'mean_hue_difference',           # tbp_lv_H                + tbp_lv_Hext    / 2\n",
    "    'std_dev_contrast',              # tbp_lv_deltaA **2 + tbp_lv_deltaB **2 + tbp_lv_deltaL **2   / 3  np.sqrt\n",
    "    'overall_color_difference',      # tbp_lv_deltaA           + tbp_lv_deltaB + tbp_lv_deltaL   / 3\n",
    "    # 'color_variance_ratio',          # tbp_lv_color_std_mean   / tbp_lv_stdLExt\n",
    "    'size_color_contrast_ratio',     # clin_size_long_diam_mm  / tbp_lv_deltaLBnorm\n",
    "    'color_range',                   # abs(tbp_lv_L - tbp_lv_Lext) + abs(tbp_lv_A - tbp_lv_Aext) + abs(tbp_lv_B - tbp_lv_Bext)\n",
    "    # 'shape_color_consistency',       # tbp_lv_eccentricity     * tbp_lv_color_std_mean\n",
    "    'border_length_ratio',           # tbp_lv_perimeterMM      / pi * sqrt(tbp_lv_areaMM2 / pi)\n",
    "\n",
    "    # # Harder to implement\n",
    "    # 'age_size_symmetry_index',       # age_approx              * clin_size_long_diam_mm * tbp_lv_symm_2axis\n",
    "    # 'index_age_size_symmetry',       # age_approx              * tbp_lv_areaMM2 * tbp_lv_symm_2axis\n",
    "    # 'color_asymmetry_index',         # tbp_lv_symm_2axis       * tbp_lv_radial_color_std_max\n",
    "    # 'color_shape_composite_index',   # tbp_lv_color_std_mean   + bp_lv_area_perim_ratio + tbp_lv_symm_2axis   / 3\n",
    "    # 'symmetry_perimeter_interaction',# tbp_lv_symm_2axis       * tbp_lv_perimeterMM\n",
    "    # 'comprehensive_lesion_index',    # tbp_lv_area_perim_ratio + tbp_lv_eccentricity + bp_lv_norm_color + tbp_lv_symm_2axis   / 4\n",
    "    # 'border_color_interaction',      # tbp_lv_norm_border      * tbp_lv_norm_color\n",
    "    # 'border_color_interaction_2',\n",
    "    # 'lesion_severity_index',         # tbp_lv_norm_border      + tbp_lv_norm_color + tbp_lv_eccentricity / 3\n",
    "    # 'shape_complexity_index',        # border_complexity       + lesion_shape_index\n",
    "    # 'lesion_visibility_score',       # tbp_lv_deltaLBnorm      + tbp_lv_norm_color\n",
    "    # 'symmetry_border_consistency',   # tbp_lv_symm_2axis       * tbp_lv_norm_border\n",
    "    # 'consistency_symmetry_border',   # tbp_lv_symm_2axis       * tbp_lv_norm_border / (tbp_lv_symm_2axis + tbp_lv_norm_border)\n",
    "    # 'border_complexity',             # tbp_lv_norm_border      + tbp_lv_symm_2axis\n",
    "    # 'color_uniformity',              # tbp_lv_color_std_mean   / tbp_lv_radial_color_std_max\n",
    "]\n",
    "\n",
    "# Categoric USER INPUT\n",
    "cat_cols = ['sex', 'anatom_site_general', 'tbp_lv_location', 'tbp_lv_location_simple']\n",
    "\n",
    "new_feature_cols = user_input_features_num + cat_cols + cv_features + derived_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:16:33.264787Z",
     "iopub.status.busy": "2024-12-12T22:16:33.264473Z",
     "iopub.status.idle": "2024-12-12T22:16:33.276946Z",
     "shell.execute_reply": "2024-12-12T22:16:33.275922Z",
     "shell.execute_reply.started": "2024-12-12T22:16:33.264765Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    return (\n",
    "        pl.read_csv(path)\n",
    "        .with_columns(\n",
    "            pl.col('age_approx').cast(pl.String).replace('NA', np.nan).cast(pl.Float64),\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col(pl.Float64).fill_nan(pl.col(pl.Float64).median()),\n",
    "        )\n",
    "        .with_columns(\n",
    "            # Basic derived features we can calculate\n",
    "            lesion_size_ratio              = pl.col('tbp_lv_minorAxisMM') / pl.col('clin_size_long_diam_mm'),\n",
    "            lesion_shape_index             = pl.col('tbp_lv_areaMM2') / (pl.col('tbp_lv_perimeterMM') ** 2),\n",
    "            hue_contrast                   = (pl.col('tbp_lv_H') - pl.col('tbp_lv_Hext')).abs(),\n",
    "            luminance_contrast             = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs(),\n",
    "            lesion_color_difference        = (pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2).sqrt(),\n",
    "        )\n",
    "        .with_columns(\n",
    "            perimeter_to_area_ratio        = pl.col('tbp_lv_perimeterMM') / pl.col('tbp_lv_areaMM2'),\n",
    "            area_to_perimeter_ratio        = pl.col('tbp_lv_areaMM2') / pl.col('tbp_lv_perimeterMM'),\n",
    "            # color_consistency              = pl.col('tbp_lv_stdL') / pl.col('tbp_lv_Lext'),\n",
    "            # consistency_color              = pl.col('tbp_lv_stdL') * pl.col('tbp_lv_Lext') / (pl.col('tbp_lv_stdL') + pl.col('tbp_lv_Lext')),\n",
    "            size_age_interaction           = pl.col('clin_size_long_diam_mm') * pl.col('age_approx'),\n",
    "            # hue_color_std_interaction      = pl.col('tbp_lv_H') * pl.col('tbp_lv_color_std_mean'),\n",
    "        )\n",
    "        .with_columns(\n",
    "            color_contrast_index           = pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL') + pl.col('tbp_lv_deltaLBnorm'),\n",
    "            log_lesion_area                = (pl.col('tbp_lv_areaMM2') + 1).log(),\n",
    "            normalized_lesion_size         = pl.col('clin_size_long_diam_mm') / pl.col('age_approx'),\n",
    "            mean_hue_difference            = (pl.col('tbp_lv_H') + pl.col('tbp_lv_Hext')) / 2,\n",
    "            std_dev_contrast               = ((pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2) / 3).sqrt(),\n",
    "            overall_color_difference       = (pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL')) / 3,\n",
    "        )\n",
    "        .with_columns(\n",
    "            # color_variance_ratio           = pl.col('tbp_lv_color_std_mean') / pl.col('tbp_lv_stdLExt'),\n",
    "            size_color_contrast_ratio      = pl.col('clin_size_long_diam_mm') / pl.col('tbp_lv_deltaLBnorm'),\n",
    "            color_range                    = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs() + (pl.col('tbp_lv_A') - pl.col('tbp_lv_Aext')).abs() + (pl.col('tbp_lv_B') - pl.col('tbp_lv_Bext')).abs(),\n",
    "            # shape_color_consistency        = pl.col('tbp_lv_eccentricity') * pl.col('tbp_lv_color_std_mean'),\n",
    "            border_length_ratio            = pl.col('tbp_lv_perimeterMM') / (2 * np.pi * (pl.col('tbp_lv_areaMM2') / np.pi).sqrt()),\n",
    "        ) # HARDER ONES AHEAD:\n",
    "        # .with_columns(\n",
    "        #     age_size_symmetry_index        = pl.col('age_approx') * pl.col('clin_size_long_diam_mm') * pl.col('tbp_lv_symm_2axis'),\n",
    "        #     index_age_size_symmetry        = pl.col('age_approx') * pl.col('tbp_lv_areaMM2') * pl.col('tbp_lv_symm_2axis'),\n",
    "        #     color_asymmetry_index          = pl.col('tbp_lv_radial_color_std_max') * pl.col('tbp_lv_symm_2axis'),\n",
    "        #     color_shape_composite_index    = (pl.col('tbp_lv_color_std_mean') + pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_symm_2axis')) / 3,\n",
    "        #     symmetry_perimeter_interaction = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_perimeterMM'),\n",
    "        #     comprehensive_lesion_index     = (pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_eccentricity') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_symm_2axis')) / 4,\n",
    "        #     border_color_interaction       = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color'),\n",
    "        #     border_color_interaction_2     = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color') / (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color')),\n",
    "        #     lesion_severity_index          = (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_eccentricity')) / 3,\n",
    "        #     shape_complexity_index         = pl.col('border_complexity') + pl.col('lesion_shape_index'),\n",
    "        #     lesion_visibility_score        = pl.col('tbp_lv_deltaLBnorm') + pl.col('tbp_lv_norm_color'),\n",
    "        #     symmetry_border_consistency    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border'),\n",
    "        #     consistency_symmetry_border    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border') / (pl.col('tbp_lv_symm_2axis') + pl.col('tbp_lv_norm_border')),\n",
    "        #     border_complexity              = pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_symm_2axis'),\n",
    "        #     color_uniformity               = pl.col('tbp_lv_color_std_mean') / (pl.col('tbp_lv_radial_color_std_max') + err),\n",
    "        # )\n",
    "        .to_pandas()\n",
    "        .set_index('isic_id')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:16:33.722160Z",
     "iopub.status.busy": "2024-12-12T22:16:33.721834Z",
     "iopub.status.idle": "2024-12-12T22:16:33.729537Z",
     "shell.execute_reply": "2024-12-12T22:16:33.728587Z",
     "shell.execute_reply.started": "2024-12-12T22:16:33.722139Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess(df_train, df_test, cat_cols, new_feature_cols):\n",
    "    # Cast original categorical columns\n",
    "    for col in cat_cols:\n",
    "        df_train[col] = df_train[col].astype('category')\n",
    "        df_test[col] = df_test[col].astype('category')\n",
    "    \n",
    "    encoder = OneHotEncoder(sparse_output=False, dtype=np.int32, handle_unknown='ignore')\n",
    "    encoder.fit(df_train[cat_cols])\n",
    "    \n",
    "    new_cat_cols = [f'onehot_{i}' for i in range(len(encoder.get_feature_names_out()))]\n",
    "    \n",
    "    # Directly assign the transformed arrays\n",
    "    df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n",
    "    df_train[new_cat_cols] = df_train[new_cat_cols].astype('category')\n",
    "    df_test[new_cat_cols] = encoder.transform(df_test[cat_cols])\n",
    "    df_test[new_cat_cols] = df_test[new_cat_cols].astype('category')\n",
    "\n",
    "    # Update feature columns\n",
    "    updated_feature_cols = [col for col in new_feature_cols if col not in cat_cols]\n",
    "    updated_feature_cols.extend(new_cat_cols)\n",
    "\n",
    "    joblib.dump(encoder, 'encoder.pkl')\n",
    "    with open('feature_columns.json', 'w') as f:\n",
    "        json.dump({\n",
    "            \"cat_cols\": new_cat_cols,\n",
    "            \"new_feature_cols\": updated_feature_cols\n",
    "        }, f)\n",
    "        \n",
    "    return df_train, df_test, new_cat_cols, updated_feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:16:34.104837Z",
     "iopub.status.busy": "2024-12-12T22:16:34.104546Z",
     "iopub.status.idle": "2024-12-12T22:16:37.017843Z",
     "shell.execute_reply": "2024-12-12T22:16:37.016930Z",
     "shell.execute_reply.started": "2024-12-12T22:16:34.104813Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "\n",
      "Creating train/test split...\n",
      "\n",
      "Train/test split sizes:\n",
      "Training set: 400981 (354 positive)\n",
      "Test set: 78 (39 positive)\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "print(\"Reading data...\")\n",
    "df_train_full = read_data(train_path)\n",
    "df_competition_test = read_data(test_path)\n",
    "df_subm = pd.read_csv(subm_path)\n",
    "\n",
    "print(\"\\nCreating train/test split...\")\n",
    "# Create balanced test set\n",
    "pos_mask = df_train_full[target_col] == 1\n",
    "pos_indices = df_train_full[pos_mask].index\n",
    "neg_indices = df_train_full[~pos_mask].index\n",
    "\n",
    "test_size = int(0.1 * len(pos_indices))\n",
    "test_pos_indices = np.random.RandomState(42).choice(pos_indices, size=test_size, replace=False)\n",
    "test_neg_indices = np.random.RandomState(42).choice(neg_indices, size=test_size, replace=False)\n",
    "test_indices = np.concatenate([test_pos_indices, test_neg_indices])\n",
    "\n",
    "# Split the data\n",
    "df_test = df_train_full.loc[test_indices].copy()\n",
    "df_train = df_train_full.drop(test_indices).copy()\n",
    "\n",
    "print(\"\\nTrain/test split sizes:\")\n",
    "print(f\"Training set: {len(df_train)} ({sum(df_train[target_col] == 1)} positive)\")\n",
    "print(f\"Test set: {len(df_test)} ({sum(df_test[target_col] == 1)} positive)\")\n",
    "\n",
    "# # Quick check of indices after split\n",
    "# print(\"\\nSample of training set indices after split:\")\n",
    "# print(df_train.index[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:18:28.787798Z",
     "iopub.status.busy": "2024-12-12T22:18:28.787366Z",
     "iopub.status.idle": "2024-12-12T22:18:28.810312Z",
     "shell.execute_reply": "2024-12-12T22:18:28.809579Z",
     "shell.execute_reply.started": "2024-12-12T22:18:28.787766Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample ISICs:\n",
      "ISIC_1885694\n",
      "ISIC_6776067\n",
      "ISIC_6242031\n",
      "ISIC_1164461\n",
      "ISIC_9877311\n",
      "\n",
      "Negative sample ISICs:\n",
      "ISIC_9153490\n",
      "ISIC_0157465\n",
      "\n",
      "All samples in a list:\n",
      "['ISIC_1885694', 'ISIC_6776067', 'ISIC_6242031', 'ISIC_1164461', 'ISIC_9877311', 'ISIC_9153490', 'ISIC_0157465']\n",
      "\n",
      "Metadata for these samples:\n",
      "              target     sex  age_approx  clin_size_long_diam_mm  \\\n",
      "isic_id                                                            \n",
      "ISIC_1885694       1    male        60.0                    2.70   \n",
      "ISIC_6776067       1    male        55.0                    5.15   \n",
      "ISIC_6242031       1    male        80.0                   16.07   \n",
      "ISIC_1164461       1                60.0                    1.13   \n",
      "ISIC_9877311       1  female        50.0                    8.16   \n",
      "ISIC_9153490       0    male        60.0                    2.60   \n",
      "ISIC_0157465       0  female        55.0                    3.30   \n",
      "\n",
      "                      tbp_lv_location anatom_site_general  \n",
      "isic_id                                                    \n",
      "ISIC_1885694              Head & Neck           head/neck  \n",
      "ISIC_6776067              Head & Neck           head/neck  \n",
      "ISIC_6242031              Head & Neck           head/neck  \n",
      "ISIC_1164461         Left Arm - Lower     upper extremity  \n",
      "ISIC_9877311  Torso Back Middle Third     posterior torso  \n",
      "ISIC_9153490        Right Arm - Lower     upper extremity  \n",
      "ISIC_0157465        Right Arm - Upper     upper extremity  \n"
     ]
    }
   ],
   "source": [
    "# Get 2 positive samples\n",
    "pos_samples = df_test[df_test[target_col] == 1].index[:5]\n",
    "print(\"Positive sample ISICs:\")\n",
    "for isic in pos_samples:\n",
    "    print(isic)\n",
    "\n",
    "# Get 2 negative samples\n",
    "neg_samples = df_test[df_test[target_col] == 0].index[:2]\n",
    "print(\"\\nNegative sample ISICs:\")\n",
    "for isic in neg_samples:\n",
    "    print(isic)\n",
    "\n",
    "# If you want them in a list\n",
    "sample_isics = list(pos_samples) + list(neg_samples)\n",
    "print(\"\\nAll samples in a list:\")\n",
    "print(sample_isics)\n",
    "\n",
    "# You can also see some metadata for these samples\n",
    "print(\"\\nMetadata for these samples:\")\n",
    "print(df_test.loc[sample_isics, ['target','sex' ,'age_approx', 'clin_size_long_diam_mm', 'tbp_lv_location', 'anatom_site_general']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:16:44.485597Z",
     "iopub.status.busy": "2024-12-12T22:16:44.485134Z",
     "iopub.status.idle": "2024-12-12T22:16:45.370265Z",
     "shell.execute_reply": "2024-12-12T22:16:45.369272Z",
     "shell.execute_reply.started": "2024-12-12T22:16:44.485573Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "\n",
      "Data ready for cross-validation:\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "print(\"Preprocessing data...\")\n",
    "df_train, df_test, new_cat_cols, updated_feature_cols = preprocess(\n",
    "    df_train, df_test, cat_cols, new_feature_cols\n",
    ")\n",
    "\n",
    "# Prepare cross-validation data\n",
    "X = df_train[updated_feature_cols]\n",
    "y = df_train[target_col]\n",
    "groups = df_train[group_col]\n",
    "\n",
    "# Setup cross-validation\n",
    "cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "print(\"\\nData ready for cross-validation:\")\n",
    "# print(f\"Features shape: {X.shape}\")\n",
    "# print(f\"Target distribution: {y.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:16:45.371842Z",
     "iopub.status.busy": "2024-12-12T22:16:45.371545Z",
     "iopub.status.idle": "2024-12-12T22:16:45.376235Z",
     "shell.execute_reply": "2024-12-12T22:16:45.375300Z",
     "shell.execute_reply.started": "2024-12-12T22:16:45.371819Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 - Tabular only model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:16:47.084284Z",
     "iopub.status.busy": "2024-12-12T22:16:47.083931Z",
     "iopub.status.idle": "2024-12-12T22:16:47.092374Z",
     "shell.execute_reply": "2024-12-12T22:16:47.091386Z",
     "shell.execute_reply.started": "2024-12-12T22:16:47.084254Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'objective':        'binary',\n",
    "    'verbosity':        -1,\n",
    "    'n_iter':           200,\n",
    "    'n_jobs':           2,\n",
    "    'boosting_type':    'gbdt',\n",
    "    'lambda_l1':        0.03335206514282942, \n",
    "    'lambda_l2':        0.005157393323802471, \n",
    "    'learning_rate':    0.030665870185795318, \n",
    "    'max_depth':        7, \n",
    "    'num_leaves':       239, \n",
    "    'colsample_bytree': 0.7573175155547233, \n",
    "    'colsample_bynode': 0.5005423904042993, \n",
    "    'bagging_fraction': 0.7937347683420382, \n",
    "    'bagging_freq':     4, \n",
    "    'min_data_in_leaf': 29, \n",
    "    'scale_pos_weight': 1.648349898918236,\n",
    "}\n",
    "\n",
    "\n",
    "estimator = VotingClassifier([\n",
    "    ('lgb1', Pipeline([\n",
    "        ('sampler', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=12)),\n",
    "        ('classifier', lgb.LGBMClassifier(**lgb_params, random_state=12)),\n",
    "    ])),\n",
    "    ('lgb2', Pipeline([\n",
    "        ('sampler', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=22)),\n",
    "        ('classifier', lgb.LGBMClassifier(**lgb_params, random_state=22)),\n",
    "    ])),\n",
    "    ('lgb3', Pipeline([\n",
    "        ('sampler', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=32)),\n",
    "        ('classifier', lgb.LGBMClassifier(**lgb_params, random_state=32)),\n",
    "    ])),\n",
    "    ('lgb4', Pipeline([\n",
    "        ('sampler', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=42)),\n",
    "        ('classifier', lgb.LGBMClassifier(**lgb_params, random_state=42)),\n",
    "    ])),\n",
    "    ('lgb5', Pipeline([\n",
    "        ('sampler', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=52)),\n",
    "        ('classifier', lgb.LGBMClassifier(**lgb_params, random_state=52)),\n",
    "    ])),\n",
    "], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:16:47.311895Z",
     "iopub.status.busy": "2024-12-12T22:16:47.311308Z",
     "iopub.status.idle": "2024-12-12T22:16:47.316800Z",
     "shell.execute_reply": "2024-12-12T22:16:47.316017Z",
     "shell.execute_reply.started": "2024-12-12T22:16:47.311827Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def custom_metric(estimator, X, y_true):\n",
    "    y_hat = estimator.predict_proba(X)[:, 1]\n",
    "    min_tpr = 0.80\n",
    "    max_fpr = abs(1 - min_tpr)\n",
    "    \n",
    "    v_gt = abs(y_true - 1)\n",
    "    v_pred = np.array([1.0 - x for x in y_hat])\n",
    "    \n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    \n",
    "    return partial_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:16:47.708584Z",
     "iopub.status.busy": "2024-12-12T22:16:47.708236Z",
     "iopub.status.idle": "2024-12-12T22:16:47.716484Z",
     "shell.execute_reply": "2024-12-12T22:16:47.715460Z",
     "shell.execute_reply.started": "2024-12-12T22:16:47.708562Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def custom_cross_val(estimator, X, y, cv, groups):\n",
    "    importances = []\n",
    "    scores = []\n",
    "    splits = list(cv.split(X, y, groups))\n",
    "    \n",
    "    # Progress bar for folds\n",
    "    fold_iterator = tqdm(enumerate(splits), \n",
    "                        total=5, \n",
    "                        desc=\"Folds\",\n",
    "                        position=0)\n",
    "    \n",
    "    # for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X, y, groups)):\n",
    "    for fold_idx, (train_idx, val_idx) in fold_iterator:\n",
    "        fold_start_time = time.time()\n",
    "        \n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Fit the model\n",
    "        estimator.fit(X_train, y_train)\n",
    "        \n",
    "        # Get scores\n",
    "        score = custom_metric(estimator, X_val, y_val)\n",
    "        scores.append(score)\n",
    "        \n",
    "        # Extract and store feature importances from each LightGBM model\n",
    "        # fold_importance = np.zeros(len(new_feature_cols))\n",
    "        fold_importance = np.zeros(len(X.columns))  # Initialize with correct number of features\n",
    "        \n",
    "        # for name, pipeline in estimator.named_estimators_.items():\n",
    "        for name, pipeline in estimator.named_estimators_.items(): \n",
    "            lgb_model = pipeline.named_steps['classifier']\n",
    "            fold_importance += lgb_model.feature_importances_\n",
    "        \n",
    "        importances.append(fold_importance / len(estimator.named_estimators_))\n",
    "        \n",
    "        fold_time = time.time() - fold_start_time\n",
    "        print(f\"Fold {fold_idx + 1} completed in {fold_time:.2f} seconds\")\n",
    "        \n",
    "        # Update fold progress bar with timing info\n",
    "        fold_iterator.set_postfix({'Score': f'{score:.4f}'})\n",
    "    \n",
    "    print('\\n')\n",
    "    return np.array(scores), np.array(importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:16:48.965362Z",
     "iopub.status.busy": "2024-12-12T22:16:48.965036Z",
     "iopub.status.idle": "2024-12-12T22:17:18.870129Z",
     "shell.execute_reply": "2024-12-12T22:17:18.869134Z",
     "shell.execute_reply.started": "2024-12-12T22:16:48.965324Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cross-validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  20%|██        | 1/5 [00:05<00:21,  5.38s/it, Score=0.1491]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 completed in 5.38 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  40%|████      | 2/5 [00:10<00:15,  5.29s/it, Score=0.1478]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 completed in 5.22 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  60%|██████    | 3/5 [00:16<00:10,  5.48s/it, Score=0.1699]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 completed in 5.72 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  80%|████████  | 4/5 [00:22<00:05,  5.93s/it, Score=0.1687]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 completed in 6.61 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds: 100%|██████████| 5/5 [00:28<00:00,  5.72s/it, Score=0.1375]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 completed in 5.67 seconds\n",
      "\n",
      "\n",
      "\n",
      "Training Complete!\n",
      "Total time: 29.89 seconds (0.50 minutes)\n",
      "\n",
      "Model Performance:\n",
      "Mean score: 0.1546\n",
      "Score std: 0.0127\n",
      "All scores: [0.14911161 0.14784121 0.16991863 0.16867588 0.13748807]\n",
      "\n",
      "Top 20 Most Important Features:\n",
      "                      feature  importance\n",
      "1      clin_size_long_diam_mm      121.32\n",
      "13                   tbp_lv_H      116.64\n",
      "18              tbp_lv_deltaB      108.80\n",
      "34   overall_color_difference       99.04\n",
      "20         tbp_lv_deltaLBnorm       96.12\n",
      "23               hue_contrast       94.56\n",
      "8                 tbp_lv_Aext       91.40\n",
      "32        mean_hue_difference       89.60\n",
      "3          tbp_lv_perimeterMM       86.56\n",
      "29       color_contrast_index       84.48\n",
      "7                    tbp_lv_A       74.68\n",
      "4          tbp_lv_minorAxisMM       73.36\n",
      "2              tbp_lv_areaMM2       70.96\n",
      "35  size_color_contrast_ratio       70.12\n",
      "31     normalized_lesion_size       69.88\n",
      "21          lesion_size_ratio       69.56\n",
      "28       size_age_interaction       67.92\n",
      "14                tbp_lv_Hext       67.48\n",
      "5         tbp_lv_eccentricity       66.68\n",
      "16                tbp_lv_Lext       64.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run cross validation with timing\n",
    "print(\"Starting cross-validation...\")\n",
    "total_start_time = time.time()\n",
    "\n",
    "# Run cross validation\n",
    "scores, all_fold_importances = custom_cross_val(\n",
    "    estimator=estimator,\n",
    "    X=X, \n",
    "    y=y,\n",
    "    cv=cv,\n",
    "    groups=groups\n",
    ")\n",
    "\n",
    "total_time = time.time() - total_start_time\n",
    "# Print timing results\n",
    "print(f\"\\nTraining Complete!\")\n",
    "print(f\"Total time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")\n",
    "\n",
    "# Print scores (equivalent to your original output)\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"Mean score: {np.mean(scores):.4f}\")\n",
    "print(f\"Score std: {np.std(scores):.4f}\")\n",
    "print(f\"All scores: {scores}\")\n",
    "\n",
    "# Print feature importances\n",
    "mean_importances = all_fold_importances.mean(axis=0)\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': updated_feature_cols,\n",
    "    'importance': mean_importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 Most Important Features:\")\n",
    "print(importance_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:17:26.403968Z",
     "iopub.status.busy": "2024-12-12T22:17:26.403638Z",
     "iopub.status.idle": "2024-12-12T22:17:28.563765Z",
     "shell.execute_reply": "2024-12-12T22:17:28.562829Z",
     "shell.execute_reply.started": "2024-12-12T22:17:26.403945Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400981, 76)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lgb1&#x27;,\n",
       "                              Pipeline(steps=[(&#x27;sampler&#x27;,\n",
       "                                               RandomUnderSampler(random_state=12,\n",
       "                                                                  sampling_strategy=0.5)),\n",
       "                                              (&#x27;classifier&#x27;,\n",
       "                                               LGBMClassifier(bagging_fraction=0.7937347683420382,\n",
       "                                                              bagging_freq=4,\n",
       "                                                              colsample_bynode=0.5005423904042993,\n",
       "                                                              colsample_bytree=0.7573175155547233,\n",
       "                                                              lambda_l1=0.03335206514282942,\n",
       "                                                              lambda_l2=0.005157393323802471,\n",
       "                                                              learning_rate=...\n",
       "                                                              bagging_freq=4,\n",
       "                                                              colsample_bynode=0.5005423904042993,\n",
       "                                                              colsample_bytree=0.7573175155547233,\n",
       "                                                              lambda_l1=0.03335206514282942,\n",
       "                                                              lambda_l2=0.005157393323802471,\n",
       "                                                              learning_rate=0.030665870185795318,\n",
       "                                                              max_depth=7,\n",
       "                                                              min_data_in_leaf=29,\n",
       "                                                              n_iter=200,\n",
       "                                                              n_jobs=2,\n",
       "                                                              num_leaves=239,\n",
       "                                                              objective=&#x27;binary&#x27;,\n",
       "                                                              random_state=52,\n",
       "                                                              scale_pos_weight=1.648349898918236,\n",
       "                                                              verbosity=-1))]))],\n",
       "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lgb1&#x27;,\n",
       "                              Pipeline(steps=[(&#x27;sampler&#x27;,\n",
       "                                               RandomUnderSampler(random_state=12,\n",
       "                                                                  sampling_strategy=0.5)),\n",
       "                                              (&#x27;classifier&#x27;,\n",
       "                                               LGBMClassifier(bagging_fraction=0.7937347683420382,\n",
       "                                                              bagging_freq=4,\n",
       "                                                              colsample_bynode=0.5005423904042993,\n",
       "                                                              colsample_bytree=0.7573175155547233,\n",
       "                                                              lambda_l1=0.03335206514282942,\n",
       "                                                              lambda_l2=0.005157393323802471,\n",
       "                                                              learning_rate=...\n",
       "                                                              bagging_freq=4,\n",
       "                                                              colsample_bynode=0.5005423904042993,\n",
       "                                                              colsample_bytree=0.7573175155547233,\n",
       "                                                              lambda_l1=0.03335206514282942,\n",
       "                                                              lambda_l2=0.005157393323802471,\n",
       "                                                              learning_rate=0.030665870185795318,\n",
       "                                                              max_depth=7,\n",
       "                                                              min_data_in_leaf=29,\n",
       "                                                              n_iter=200,\n",
       "                                                              n_jobs=2,\n",
       "                                                              num_leaves=239,\n",
       "                                                              objective=&#x27;binary&#x27;,\n",
       "                                                              random_state=52,\n",
       "                                                              scale_pos_weight=1.648349898918236,\n",
       "                                                              verbosity=-1))]))],\n",
       "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgb1</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=12, sampling_strategy=0.5)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.7937347683420382, bagging_freq=4,\n",
       "               colsample_bynode=0.5005423904042993,\n",
       "               colsample_bytree=0.7573175155547233,\n",
       "               lambda_l1=0.03335206514282942, lambda_l2=0.005157393323802471,\n",
       "               learning_rate=0.030665870185795318, max_depth=7,\n",
       "               min_data_in_leaf=29, n_iter=200, n_jobs=2, num_leaves=239,\n",
       "               objective=&#x27;binary&#x27;, random_state=12,\n",
       "               scale_pos_weight=1.648349898918236, verbosity=-1)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgb2</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=22, sampling_strategy=0.5)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.7937347683420382, bagging_freq=4,\n",
       "               colsample_bynode=0.5005423904042993,\n",
       "               colsample_bytree=0.7573175155547233,\n",
       "               lambda_l1=0.03335206514282942, lambda_l2=0.005157393323802471,\n",
       "               learning_rate=0.030665870185795318, max_depth=7,\n",
       "               min_data_in_leaf=29, n_iter=200, n_jobs=2, num_leaves=239,\n",
       "               objective=&#x27;binary&#x27;, random_state=22,\n",
       "               scale_pos_weight=1.648349898918236, verbosity=-1)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgb3</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=32, sampling_strategy=0.5)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.7937347683420382, bagging_freq=4,\n",
       "               colsample_bynode=0.5005423904042993,\n",
       "               colsample_bytree=0.7573175155547233,\n",
       "               lambda_l1=0.03335206514282942, lambda_l2=0.005157393323802471,\n",
       "               learning_rate=0.030665870185795318, max_depth=7,\n",
       "               min_data_in_leaf=29, n_iter=200, n_jobs=2, num_leaves=239,\n",
       "               objective=&#x27;binary&#x27;, random_state=32,\n",
       "               scale_pos_weight=1.648349898918236, verbosity=-1)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgb4</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=42, sampling_strategy=0.5)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.7937347683420382, bagging_freq=4,\n",
       "               colsample_bynode=0.5005423904042993,\n",
       "               colsample_bytree=0.7573175155547233,\n",
       "               lambda_l1=0.03335206514282942, lambda_l2=0.005157393323802471,\n",
       "               learning_rate=0.030665870185795318, max_depth=7,\n",
       "               min_data_in_leaf=29, n_iter=200, n_jobs=2, num_leaves=239,\n",
       "               objective=&#x27;binary&#x27;, random_state=42,\n",
       "               scale_pos_weight=1.648349898918236, verbosity=-1)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgb5</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=52, sampling_strategy=0.5)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.7937347683420382, bagging_freq=4,\n",
       "               colsample_bynode=0.5005423904042993,\n",
       "               colsample_bytree=0.7573175155547233,\n",
       "               lambda_l1=0.03335206514282942, lambda_l2=0.005157393323802471,\n",
       "               learning_rate=0.030665870185795318, max_depth=7,\n",
       "               min_data_in_leaf=29, n_iter=200, n_jobs=2, num_leaves=239,\n",
       "               objective=&#x27;binary&#x27;, random_state=52,\n",
       "               scale_pos_weight=1.648349898918236, verbosity=-1)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('lgb1',\n",
       "                              Pipeline(steps=[('sampler',\n",
       "                                               RandomUnderSampler(random_state=12,\n",
       "                                                                  sampling_strategy=0.5)),\n",
       "                                              ('classifier',\n",
       "                                               LGBMClassifier(bagging_fraction=0.7937347683420382,\n",
       "                                                              bagging_freq=4,\n",
       "                                                              colsample_bynode=0.5005423904042993,\n",
       "                                                              colsample_bytree=0.7573175155547233,\n",
       "                                                              lambda_l1=0.03335206514282942,\n",
       "                                                              lambda_l2=0.005157393323802471,\n",
       "                                                              learning_rate=...\n",
       "                                                              bagging_freq=4,\n",
       "                                                              colsample_bynode=0.5005423904042993,\n",
       "                                                              colsample_bytree=0.7573175155547233,\n",
       "                                                              lambda_l1=0.03335206514282942,\n",
       "                                                              lambda_l2=0.005157393323802471,\n",
       "                                                              learning_rate=0.030665870185795318,\n",
       "                                                              max_depth=7,\n",
       "                                                              min_data_in_leaf=29,\n",
       "                                                              n_iter=200,\n",
       "                                                              n_jobs=2,\n",
       "                                                              num_leaves=239,\n",
       "                                                              objective='binary',\n",
       "                                                              random_state=52,\n",
       "                                                              scale_pos_weight=1.648349898918236,\n",
       "                                                              verbosity=-1))]))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train, df_test, new_cat_cols, updated_feature_cols = preprocess(\n",
    "#     df_train, df_test, cat_cols, new_feature_cols\n",
    "# )\n",
    "\n",
    "X, y = df_train[updated_feature_cols], df_train[target_col] \n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "estimator.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:17:28.566195Z",
     "iopub.status.busy": "2024-12-12T22:17:28.565469Z",
     "iopub.status.idle": "2024-12-12T22:17:28.603228Z",
     "shell.execute_reply": "2024-12-12T22:17:28.602203Z",
     "shell.execute_reply.started": "2024-12-12T22:17:28.566160Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(estimator, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 - Hybrid Model (CNN + Tabular Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:06:06.401569Z",
     "iopub.status.busy": "2024-12-12T22:06:06.401309Z",
     "iopub.status.idle": "2024-12-12T22:06:06.405533Z",
     "shell.execute_reply": "2024-12-12T22:06:06.404489Z",
     "shell.execute_reply.started": "2024-12-12T22:06:06.401548Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_h5 = root / 'train-image.hdf5'\n",
    "test_h5 = root / 'test-image.hdf5'\n",
    "\n",
    "# sampling_ratio = 1 # Sampling ratio for hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:06:06.408579Z",
     "iopub.status.busy": "2024-12-12T22:06:06.407740Z",
     "iopub.status.idle": "2024-12-12T22:06:06.415617Z",
     "shell.execute_reply": "2024-12-12T22:06:06.414964Z",
     "shell.execute_reply.started": "2024-12-12T22:06:06.408545Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ImageFeatureExtractor(nn.Module):\n",
    "    \"\"\"ResNet18 based feature extractor\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Load pretrained ResNet18\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        # Remove the final classification layer\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Extract features and remove extra dimensions\n",
    "        x = self.features(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:06:06.417174Z",
     "iopub.status.busy": "2024-12-12T22:06:06.416893Z",
     "iopub.status.idle": "2024-12-12T22:06:06.429819Z",
     "shell.execute_reply": "2024-12-12T22:06:06.429051Z",
     "shell.execute_reply.started": "2024-12-12T22:06:06.417154Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_augmentations():\n",
    "    \"\"\"Create augmentation pipeline for positive samples\"\"\"\n",
    "    return A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.ColorJitter(\n",
    "            brightness=0.2,\n",
    "            contrast=0.2,\n",
    "            saturation=0.2,\n",
    "            hue=0.1,\n",
    "            p=0.5\n",
    "        ),\n",
    "        # Careful with these since they might affect medical features\n",
    "        A.GaussNoise(p=0.2),\n",
    "        A.Blur(p=0.2),\n",
    "    ])\n",
    "\n",
    "def extract_image_features(h5_path, df_index, target_series=None, batch_size=32, device='cuda', augment_positives=True):\n",
    "    \"\"\"Extract features from images in batches with optional augmentation\"\"\"\n",
    "    model = ImageFeatureExtractor().to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Setup augmentations if needed\n",
    "    aug = create_augmentations() if augment_positives else None\n",
    "    \n",
    "    features_list = []\n",
    "    valid_ids = []\n",
    "    error_ids = []\n",
    "    \n",
    "    with h5py.File(h5_path, 'r') as h5_file:\n",
    "        for i in tqdm(range(0, len(df_index), batch_size), desc=\"Extracting image features\"):\n",
    "            batch_ids = df_index[i:i + batch_size]\n",
    "            batch_images = []\n",
    "            batch_valid_ids = []\n",
    "            \n",
    "            for isic_id in batch_ids:\n",
    "                try:\n",
    "                    # Load image\n",
    "                    img_bytes = h5_file[isic_id][()]\n",
    "                    image = Image.open(io.BytesIO(img_bytes)).convert('RGB')\n",
    "                    image = np.array(image)\n",
    "                    \n",
    "                    # Apply augmentation for positive samples\n",
    "                    if augment_positives and target_series is not None and target_series[isic_id] == 1:\n",
    "                        # Create 2 augmented versions of each positive sample\n",
    "                        augmented = [aug(image=image)['image'] for _ in range(2)]\n",
    "                        for aug_img in augmented:\n",
    "                            aug_tensor = transform(Image.fromarray(aug_img))\n",
    "                            batch_images.append(aug_tensor)\n",
    "                            batch_valid_ids.append(isic_id)  # Duplicate ID for augmented samples\n",
    "                    \n",
    "                    # Always include original image\n",
    "                    image_tensor = transform(Image.fromarray(image))\n",
    "                    batch_images.append(image_tensor)\n",
    "                    batch_valid_ids.append(isic_id)\n",
    "                    \n",
    "                except KeyError:\n",
    "                    error_ids.append(isic_id)\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image {isic_id}: {str(e)}\")\n",
    "                    error_ids.append(isic_id)\n",
    "                    continue\n",
    "            \n",
    "            if not batch_images:\n",
    "                continue\n",
    "                \n",
    "            batch_tensor = torch.stack(batch_images).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                batch_features = model(batch_tensor).cpu().numpy()\n",
    "            \n",
    "            features_list.append(batch_features)\n",
    "            valid_ids.extend(batch_valid_ids)\n",
    "            \n",
    "            del batch_tensor\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    if not features_list:\n",
    "        print(f\"\\nFailed to find any valid images out of {len(df_index)} requested.\")\n",
    "        print(f\"Error IDs sample: {error_ids[:10]}\")\n",
    "        raise ValueError(\"No valid images found\")\n",
    "        \n",
    "    return np.vstack(features_list), valid_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:06:06.431089Z",
     "iopub.status.busy": "2024-12-12T22:06:06.430813Z",
     "iopub.status.idle": "2024-12-12T22:06:06.444764Z",
     "shell.execute_reply": "2024-12-12T22:06:06.443833Z",
     "shell.execute_reply.started": "2024-12-12T22:06:06.431068Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_sampling_ratio(n_pos, n_neg, n_augmentations=3):\n",
    "    total_pos = n_pos * (1 + n_augmentations)  # original + augmented\n",
    "    if (total_pos / n_neg) > 0.5:\n",
    "        print(\"Warning: Sampling ratio is high!\")\n",
    "    return min(0.5, total_pos / n_neg)  # minimum ratio of 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:06:06.628806Z",
     "iopub.status.busy": "2024-12-12T22:06:06.628547Z",
     "iopub.status.idle": "2024-12-12T22:06:06.633972Z",
     "shell.execute_reply": "2024-12-12T22:06:06.633052Z",
     "shell.execute_reply.started": "2024-12-12T22:06:06.628785Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_sampling_ratio(n_pos, n_neg, n_augmentations=3):\n",
    "    \"\"\"\n",
    "    Calculate sampling ratio bounded between 0.01 and 0.5\n",
    "    \"\"\"\n",
    "    total_pos = n_pos * (1 + n_augmentations)  # original + augmented\n",
    "    raw_ratio = total_pos / n_neg\n",
    "    \n",
    "    # Bound the ratio between 0.01 and 0.5\n",
    "    ratio = max(0.01, min(0.5, raw_ratio))\n",
    "    \n",
    "    # Add warning messages for visibility\n",
    "    if raw_ratio > 0.5:\n",
    "        print(f\"Warning: Raw sampling ratio {raw_ratio:.3f} was capped to 0.5\")\n",
    "    elif raw_ratio < 0.01:\n",
    "        print(f\"Warning: Raw sampling ratio {raw_ratio:.3f} was raised to 0.01\")\n",
    "        \n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:06:07.049316Z",
     "iopub.status.busy": "2024-12-12T22:06:07.049069Z",
     "iopub.status.idle": "2024-12-12T22:06:07.069376Z",
     "shell.execute_reply": "2024-12-12T22:06:07.068443Z",
     "shell.execute_reply.started": "2024-12-12T22:06:07.049297Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_hybrid_model(df_train, df_test, train_h5, sample_size=None):\n",
    "    \"\"\"Train and evaluate both original and hybrid models\"\"\"\n",
    "    \n",
    "    if sample_size is not None:\n",
    "        # First determine minimum number of positive samples needed\n",
    "        min_pos_samples = 50  # Set a minimum to ensure each fold has positive samples\n",
    "        \n",
    "        # Sample positive cases first\n",
    "        pos_mask = df_train[target_col] == 1\n",
    "        pos_indices = df_train[pos_mask].index\n",
    "        neg_indices = df_train[~pos_mask].index\n",
    "        \n",
    "        # Take all positive samples if we have fewer than min_pos_samples\n",
    "        n_pos = min(len(pos_indices), max(min_pos_samples, sample_size // 10))\n",
    "        # Calculate corresponding negative samples to maintain rough class balance\n",
    "        n_neg = min(len(neg_indices), sample_size - n_pos)\n",
    "        \n",
    "        print(f\"Sampling {n_pos} positive and {n_neg} negative cases...\")\n",
    "        \n",
    "        sampled_pos = np.random.choice(pos_indices, size=n_pos, replace=False)\n",
    "        sampled_neg = np.random.choice(neg_indices, size=n_neg, replace=False)\n",
    "        \n",
    "        sampled_indices = np.concatenate([sampled_pos, sampled_neg])\n",
    "        np.random.shuffle(sampled_indices)  # Shuffle to mix positive and negative cases\n",
    "        df_train = df_train.loc[sampled_indices]\n",
    "    \n",
    "    print(\"\\nStarting with data sizes:\")\n",
    "    print(f\"Training set: {len(df_train)} samples ({sum(df_train[target_col] == 1)} positive)\")\n",
    "    print(f\"Class ratio (neg/pos): {(len(df_train) - sum(df_train[target_col] == 1)) / sum(df_train[target_col] == 1):.2f}\")\n",
    "    print(f\"Test set: {len(df_test)} samples ({sum(df_test[target_col] == 1)} positive)\")\n",
    "\n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    # Extract CNN features with better error handling\n",
    "    print(\"\\nExtracting CNN features for training set...\")\n",
    "    try:\n",
    "        train_cnn_features, train_valid_ids = extract_image_features(\n",
    "            train_h5, \n",
    "            df_train.index,\n",
    "            target_series=df_train[target_col],  # Pass targets for augmentation\n",
    "            batch_size=32,\n",
    "            augment_positives=True  # Enable augmentation\n",
    "        )\n",
    "        print(f\"Successfully extracted features for {len(train_valid_ids)} training images (including augmentations)\")\n",
    "        \n",
    "        print(\"\\nExtracting CNN features for test set...\")\n",
    "        test_cnn_features, test_valid_ids = extract_image_features(\n",
    "            train_h5,\n",
    "            df_test.index,\n",
    "            augment_positives=False,  # No augmentation for test set\n",
    "            batch_size=32\n",
    "        )\n",
    "        print(f\"Successfully extracted features for {len(test_valid_ids)} test images\")\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(\"\\nError during feature extraction. Checking HDF5 files...\")\n",
    "        with h5py.File(train_h5, 'r') as f:\n",
    "            print(f\"\\nTraining HDF5 structure:\")\n",
    "            print(f\"Number of images: {len(f.keys())}\")\n",
    "            print(f\"Sample keys: {list(f.keys())[:5]}\")\n",
    "            \n",
    "        with h5py.File(train_h5, 'r') as f:\n",
    "            print(f\"\\nTest HDF5 structure:\")\n",
    "            print(f\"Number of images: {len(f.keys())}\")\n",
    "            print(f\"Sample keys: {list(f.keys())[:5]}\")\n",
    "            \n",
    "        raise ValueError(\"Feature extraction failed. Check HDF5 file paths and contents.\") from e\n",
    "\n",
    "    # Create feature names for CNN features\n",
    "    cnn_feature_names = [f'cnn_feature_{i}' for i in range(train_cnn_features.shape[1])]\n",
    "    \n",
    "    # Create DataFrames with CNN features\n",
    "    train_cnn_df = pd.DataFrame(\n",
    "        train_cnn_features, \n",
    "        index=train_valid_ids,\n",
    "        columns=cnn_feature_names\n",
    "    )\n",
    "    \n",
    "    test_cnn_df = pd.DataFrame(\n",
    "        test_cnn_features,\n",
    "        index=test_valid_ids,\n",
    "        columns=cnn_feature_names\n",
    "    )\n",
    "    \n",
    "    # Combine with tabular features\n",
    "    X_train_hybrid = pd.concat([\n",
    "        df_train.loc[train_valid_ids, updated_feature_cols],\n",
    "        train_cnn_df\n",
    "    ], axis=1)\n",
    "    \n",
    "    X_test_hybrid = pd.concat([\n",
    "        df_test.loc[test_valid_ids, updated_feature_cols],\n",
    "        test_cnn_df\n",
    "    ], axis=1)\n",
    "    \n",
    "    y_train_hybrid = df_train.loc[train_valid_ids, target_col]\n",
    "    y_test_hybrid = df_test.loc[test_valid_ids, target_col]\n",
    "    groups_train_hybrid = df_train.loc[train_valid_ids, group_col]\n",
    "    \n",
    "    print(\"\\nHybrid feature matrix shapes:\")\n",
    "    print(f\"Training: {X_train_hybrid.shape}\")\n",
    "    print(f\"Testing: {X_test_hybrid.shape}\")\n",
    "\n",
    "    sampling_ratio = get_sampling_ratio(n_pos, n_neg)\n",
    "    \n",
    "    # Create hybrid model with same structure as original but with updated sampling ratio\n",
    "    hybrid_model = VotingClassifier([\n",
    "        ('lgb1', Pipeline([\n",
    "            ('sampler', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=12)),\n",
    "            ('classifier', lgb.LGBMClassifier(**lgb_params, random_state=12)),\n",
    "        ])),\n",
    "        ('lgb2', Pipeline([\n",
    "            ('sampler', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=22)),\n",
    "            ('classifier', lgb.LGBMClassifier(**lgb_params, random_state=22)),\n",
    "        ])),\n",
    "        ('lgb3', Pipeline([\n",
    "            ('sampler', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=32)),\n",
    "            ('classifier', lgb.LGBMClassifier(**lgb_params, random_state=32)),\n",
    "        ])),\n",
    "        ('lgb4', Pipeline([\n",
    "            ('sampler', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=42)),\n",
    "            ('classifier', lgb.LGBMClassifier(**lgb_params, random_state=42)),\n",
    "        ])),\n",
    "        ('lgb5', Pipeline([\n",
    "            ('sampler', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=52)),\n",
    "            ('classifier', lgb.LGBMClassifier(**lgb_params, random_state=52)),\n",
    "        ])),\n",
    "    ], voting='soft')\n",
    "    \n",
    "    # Cross-validation for hybrid model\n",
    "    print(\"\\nEvaluating hybrid model...\")\n",
    "    hybrid_scores, hybrid_importances = custom_cross_val(\n",
    "        estimator=hybrid_model,\n",
    "        X=X_train_hybrid,\n",
    "        y=y_train_hybrid,\n",
    "        cv=cv,\n",
    "        groups=groups_train_hybrid\n",
    "    )\n",
    "\n",
    "    total_time = time.time() - total_start_time\n",
    "    print(f\"\\nTraining Complete!\")\n",
    "    print(f\"Total time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")\n",
    "    \n",
    "    print(f\"Hybrid model mean CV score: {np.mean(hybrid_scores):.4f} (±{np.std(hybrid_scores):.4f})\")\n",
    "    \n",
    "    # Feature importance analysis\n",
    "    mean_importances = hybrid_importances.mean(axis=0)\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': list(X_train_hybrid.columns),\n",
    "        'importance': mean_importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 20 Most Important Features:\")\n",
    "    print(importance_df.head(20))\n",
    "    \n",
    "    # Train final hybrid model\n",
    "    print(\"\\nTraining final hybrid model...\")\n",
    "    hybrid_model.fit(X_train_hybrid, y_train_hybrid)\n",
    "    \n",
    "    # Save the hybrid model and feature info\n",
    "    print(\"\\nSaving hybrid model...\")\n",
    "    \n",
    "    model_artifacts = {\n",
    "        'model': hybrid_model,\n",
    "        'feature_columns': list(X_train_hybrid.columns),\n",
    "        'cnn_feature_names': cnn_feature_names,\n",
    "        'feature_extractor': ImageFeatureExtractor().to('cpu'),  # Save CNN model too\n",
    "        'transform': transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    with open('hybrid_model_full.pkl', 'wb') as f:\n",
    "        pickle.dump(model_artifacts, f)\n",
    "\n",
    "\n",
    "    # with open('hybrid_model.pkl', 'wb') as f:\n",
    "    #     pickle.dump({\n",
    "    #         'model': hybrid_model,\n",
    "    #         'feature_columns': list(X_train_hybrid.columns),\n",
    "    #         'cnn_feature_names': cnn_feature_names\n",
    "    #     }, f)\n",
    "    print(\"\\nSaved Succesfully!\")\n",
    "    \n",
    "    return hybrid_scores, importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:06:07.974175Z",
     "iopub.status.busy": "2024-12-12T22:06:07.973836Z",
     "iopub.status.idle": "2024-12-12T22:07:25.741188Z",
     "shell.execute_reply": "2024-12-12T22:07:25.740356Z",
     "shell.execute_reply.started": "2024-12-12T22:06:07.974151Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 100 positive and 900 negative cases...\n",
      "\n",
      "Starting with data sizes:\n",
      "Training set: 1000 samples (100 positive)\n",
      "Class ratio (neg/pos): 9.00\n",
      "Test set: 78 samples (39 positive)\n",
      "\n",
      "Extracting CNN features for training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 151MB/s] \n",
      "Extracting image features: 100%|██████████| 32/32 [00:13<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted features for 1200 training images (including augmentations)\n",
      "\n",
      "Extracting CNN features for test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting image features: 100%|██████████| 3/3 [00:00<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted features for 78 test images\n",
      "\n",
      "Hybrid feature matrix shapes:\n",
      "Training: (1200, 588)\n",
      "Testing: (78, 588)\n",
      "\n",
      "Evaluating hybrid model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  20%|██        | 1/5 [00:10<00:42, 10.63s/it, Score=0.1730]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 completed in 10.63 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  40%|████      | 2/5 [00:21<00:31, 10.60s/it, Score=0.1691]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 completed in 10.58 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  60%|██████    | 3/5 [00:29<00:19,  9.74s/it, Score=0.1441]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 completed in 8.71 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  80%|████████  | 4/5 [00:38<00:09,  9.12s/it, Score=0.1592]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 completed in 8.16 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds: 100%|██████████| 5/5 [00:48<00:00,  9.74s/it, Score=0.1618]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 completed in 10.61 seconds\n",
      "\n",
      "\n",
      "\n",
      "Training Complete!\n",
      "Total time: 64.56 seconds (1.08 minutes)\n",
      "Hybrid model mean CV score: 0.1615 (±0.0100)\n",
      "\n",
      "Top 20 Most Important Features:\n",
      "                      feature  importance\n",
      "1      clin_size_long_diam_mm       79.00\n",
      "13                   tbp_lv_H       68.40\n",
      "32        mean_hue_difference       56.32\n",
      "14                tbp_lv_Hext       50.24\n",
      "34   overall_color_difference       38.44\n",
      "18              tbp_lv_deltaB       36.20\n",
      "2              tbp_lv_areaMM2       33.28\n",
      "4          tbp_lv_minorAxisMM       33.08\n",
      "28       size_age_interaction       27.40\n",
      "26    perimeter_to_area_ratio       27.04\n",
      "29       color_contrast_index       26.92\n",
      "3          tbp_lv_perimeterMM       25.08\n",
      "109            cnn_feature_33       22.00\n",
      "27    area_to_perimeter_ratio       21.28\n",
      "389           cnn_feature_313       20.88\n",
      "30            log_lesion_area       19.72\n",
      "361           cnn_feature_285       19.40\n",
      "23               hue_contrast       18.96\n",
      "86             cnn_feature_10       18.36\n",
      "448           cnn_feature_372       17.20\n",
      "\n",
      "Training final hybrid model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving hybrid model...\n",
      "\n",
      "Saved Succesfully!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    hybrid_scores, importance_df = train_and_evaluate_hybrid_model(\n",
    "        df_train, df_test,\n",
    "        train_h5,\n",
    "        # sample_size= len(df_train)  # take subset of df_train or entire df_train\n",
    "        sample_size= 1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on both models on holdout test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:10:26.008418Z",
     "iopub.status.busy": "2024-12-12T22:10:26.007694Z",
     "iopub.status.idle": "2024-12-12T22:10:26.025319Z",
     "shell.execute_reply": "2024-12-12T22:10:26.024480Z",
     "shell.execute_reply.started": "2024-12-12T22:10:26.008389Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import h5py\n",
    "from PIL import Image\n",
    "import io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "def custom_metric_test(y_true, y_pred):\n",
    "    \"\"\"Calculate partial AUC for test set predictions\"\"\"\n",
    "    min_tpr = 0.80\n",
    "    max_fpr = abs(1 - min_tpr)\n",
    "    \n",
    "    v_gt = abs(y_true - 1)\n",
    "    v_pred = np.array([1.0 - x for x in y_pred])\n",
    "    \n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    \n",
    "    return partial_auc\n",
    "\n",
    "def evaluate_tabular_model(model_path, df_test, feature_cols=None):\n",
    "    \"\"\"Evaluate the tabular-only model\"\"\"\n",
    "    # Load the model\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model_data = pickle.load(f)\n",
    "    \n",
    "    # Handle both dictionary and direct model cases\n",
    "    if isinstance(model_data, dict):\n",
    "        model = model_data['model']\n",
    "        feature_cols = model_data.get(\"feature_columns\") or model_data.get(\"new_feature_cols\")\n",
    "    else:\n",
    "        model = model_data\n",
    "        if feature_cols is None:\n",
    "            # If no feature columns provided, use the ones from df_test\n",
    "            feature_cols = [col for col in df_test.columns if col != 'target' and col != 'patient_id']\n",
    "    \n",
    "    # Prepare test features\n",
    "    X_test = df_test[feature_cols]\n",
    "    y_test = df_test['target']\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    score = custom_metric_test(y_test, y_pred)\n",
    "    \n",
    "    return score, y_pred\n",
    "\n",
    "def evaluate_hybrid_model(model_path, df_test, test_h5_path, batch_size=32, device='cuda'):\n",
    "    \"\"\"Evaluate the hybrid model\"\"\"\n",
    "    # Load the hybrid model and all necessary components\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model_data = pickle.load(f)\n",
    "    \n",
    "    model = model_data['model']\n",
    "    feature_columns = model_data['feature_columns']\n",
    "    cnn_feature_names = model_data['cnn_feature_names']\n",
    "    feature_extractor = model_data['feature_extractor'].to(device)\n",
    "    transform = model_data['transform']\n",
    "    \n",
    "    feature_extractor.eval()\n",
    "    \n",
    "    # Extract CNN features for test set\n",
    "    print(\"Extracting CNN features for test set...\")\n",
    "    test_cnn_features, test_valid_ids = [], []\n",
    "    \n",
    "    with h5py.File(test_h5_path, 'r') as h5_file:\n",
    "        for i in tqdm(range(0, len(df_test), batch_size)):\n",
    "            batch_ids = df_test.index[i:i + batch_size]\n",
    "            batch_images = []\n",
    "            batch_valid_ids = []\n",
    "            \n",
    "            for isic_id in batch_ids:\n",
    "                try:\n",
    "                    # Load and process image\n",
    "                    img_bytes = h5_file[isic_id][()]\n",
    "                    image = Image.open(io.BytesIO(img_bytes)).convert('RGB')\n",
    "                    image_tensor = transform(image)\n",
    "                    batch_images.append(image_tensor)\n",
    "                    batch_valid_ids.append(isic_id)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image {isic_id}: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            if not batch_images:\n",
    "                continue\n",
    "                \n",
    "            # Process batch\n",
    "            batch_tensor = torch.stack(batch_images).to(device)\n",
    "            with torch.no_grad():\n",
    "                batch_features = feature_extractor(batch_tensor).cpu().numpy()\n",
    "            \n",
    "            test_cnn_features.append(batch_features)\n",
    "            test_valid_ids.extend(batch_valid_ids)\n",
    "            \n",
    "            del batch_tensor\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Combine features\n",
    "    test_cnn_features = np.vstack(test_cnn_features)\n",
    "    test_cnn_df = pd.DataFrame(\n",
    "        test_cnn_features,\n",
    "        index=test_valid_ids,\n",
    "        columns=cnn_feature_names\n",
    "    )\n",
    "    \n",
    "    # Create final feature matrix\n",
    "    X_test_hybrid = pd.concat([\n",
    "        df_test.loc[test_valid_ids, [col for col in feature_columns if col not in cnn_feature_names]],\n",
    "        test_cnn_df\n",
    "    ], axis=1)\n",
    "    \n",
    "    y_test = df_test.loc[test_valid_ids, 'target']\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = model.predict_proba(X_test_hybrid)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    score = custom_metric_test(y_test, y_pred)\n",
    "    \n",
    "    return score, y_pred, test_valid_ids\n",
    "\n",
    "def compare_models(df_test, tabular_model_path, hybrid_model_path, test_h5_path, feature_cols=None):\n",
    "    \"\"\"Compare both models on the test set\"\"\"\n",
    "    print(\"Evaluating tabular model...\")\n",
    "    tab_score, tab_pred = evaluate_tabular_model(tabular_model_path, df_test, feature_cols)\n",
    "    \n",
    "    print(\"\\nEvaluating hybrid model...\")\n",
    "    hyb_score, hyb_pred, valid_ids = evaluate_hybrid_model(\n",
    "        hybrid_model_path, df_test, test_h5_path\n",
    "    )\n",
    "    \n",
    "    # Create comparison DataFrame\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'True_Label': df_test.loc[valid_ids, 'target'],\n",
    "        'Tabular_Pred': tab_pred[df_test.index.isin(valid_ids)],  # Filter to match valid_ids\n",
    "        'Hybrid_Pred': hyb_pred\n",
    "    })\n",
    "    \n",
    "    print(\"\\nModel Comparison Results:\")\n",
    "    print(f\"Tabular Model pAUC: {tab_score:.4f}\")\n",
    "    print(f\"Hybrid Model pAUC:  {hyb_score:.4f}\")\n",
    "    \n",
    "    return comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:24:20.333502Z",
     "iopub.status.busy": "2024-12-12T22:24:20.332540Z",
     "iopub.status.idle": "2024-12-12T22:24:20.338172Z",
     "shell.execute_reply": "2024-12-12T22:24:20.337176Z",
     "shell.execute_reply.started": "2024-12-12T22:24:20.333459Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# # print(\"\\nContents of /kaggle directory:\")\n",
    "# # print(os.listdir('/kaggle'))\n",
    "\n",
    "# # print(\"\\nContents of Model directory (if it exists):\")\n",
    "# # if os.path.exists('/kaggle/input/models/pytorch/default/1'):\n",
    "# #     print(os.listdir('/kaggle/input/models/pytorch/default/1'))\n",
    "\n",
    "# # print(\"\\nContents of /kaggle/working directory:\")\n",
    "# # print(os.listdir('/kaggle/working'))\n",
    "\n",
    "# if os.path.exists('/kaggle/working/'):\n",
    "#     print(os.listdir('/kaggle/working'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:17:36.125202Z",
     "iopub.status.busy": "2024-12-12T22:17:36.124898Z",
     "iopub.status.idle": "2024-12-12T22:17:37.281984Z",
     "shell.execute_reply": "2024-12-12T22:17:37.281166Z",
     "shell.execute_reply.started": "2024-12-12T22:17:36.125182Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns we're using:\n",
      "Number of features: 76\n",
      "Sample features: ['age_approx', 'clin_size_long_diam_mm', 'tbp_lv_areaMM2', 'tbp_lv_perimeterMM', 'tbp_lv_minorAxisMM']\n",
      "Evaluating tabular model...\n",
      "\n",
      "Evaluating hybrid model...\n",
      "Extracting CNN features for test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Comparison Results:\n",
      "Tabular Model pAUC: 0.1695\n",
      "Hybrid Model pAUC:  0.1285\n"
     ]
    }
   ],
   "source": [
    "# First make sure we have the feature columns\n",
    "print(\"Feature columns we're using:\")\n",
    "print(f\"Number of features: {len(updated_feature_cols)}\")\n",
    "print(f\"Sample features: {updated_feature_cols[:5]}\")\n",
    "\n",
    "comparison_df = compare_models(\n",
    "    df_test=df_test,\n",
    "    tabular_model_path='/kaggle/working/model.pkl',\n",
    "    # hybrid_model_path='/kaggle/input/models/pytorch/default/1/hybrid_model_full.pkl',\n",
    "    hybrid_model_path='/kaggle/working/hybrid_model_full.pkl',\n",
    "    test_h5_path=train_h5,\n",
    "    feature_cols=updated_feature_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T19:22:07.522986Z",
     "iopub.status.busy": "2024-12-12T19:22:07.522100Z",
     "iopub.status.idle": "2024-12-12T19:22:08.628695Z",
     "shell.execute_reply": "2024-12-12T19:22:08.627838Z",
     "shell.execute_reply.started": "2024-12-12T19:22:07.522960Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking tabular model contents:\n",
      "Tabular model type: <class 'sklearn.ensemble._voting.VotingClassifier'>\n",
      "\n",
      "Checking hybrid model contents:\n",
      "Hybrid model type: <class 'dict'>\n",
      "Hybrid model keys: dict_keys(['model', 'feature_columns', 'cnn_feature_names', 'feature_extractor', 'transform'])\n"
     ]
    }
   ],
   "source": [
    "# First let's look at what we actually saved\n",
    "import pickle\n",
    "\n",
    "print(\"Checking tabular model contents:\")\n",
    "with open('/kaggle/input/models/pytorch/default/1/model.pkl', 'rb') as f:\n",
    "    tabular_model = pickle.load(f)\n",
    "print(f\"Tabular model type: {type(tabular_model)}\")\n",
    "\n",
    "print(\"\\nChecking hybrid model contents:\")\n",
    "with open('/kaggle/input/models/pytorch/default/1/hybrid_model_full.pkl', 'rb') as f:\n",
    "    hybrid_model = pickle.load(f)\n",
    "print(f\"Hybrid model type: {type(hybrid_model)}\")\n",
    "print(f\"Hybrid model keys: {hybrid_model.keys() if isinstance(hybrid_model, dict) else 'Not a dictionary'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Final Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model 1 - Tabular Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# df_train_full_processed, df_competition_test_processed, new_cat_cols, updated_feature_cols = preprocess(\n",
    "#     df_train_full, df_competition_test, cat_cols, new_feature_cols\n",
    "# )\n",
    "\n",
    "# X, y = df_train_full_processed[updated_feature_cols], df_train_full_processed[target_col] # UPDATE TO FULL TRAINING SET !\n",
    "\n",
    "# estimator.fit(X, y)\n",
    "\n",
    "# with open('model.pkl', 'wb') as file:\n",
    "#     pickle.dump(estimator, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model 2 - Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Not building until test and CV scores improve..."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9094797,
     "sourceId": 63056,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 189882,
     "modelInstanceId": 167566,
     "sourceId": 196497,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
